{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08c69be4-1188-48fe-b0c4-b2627a58facb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 13:50:55.649581: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-04 13:50:56.695684: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# ----------------- Import Libraries -----------------\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score, classification_report\n",
    "\n",
    "import seaborn as sns\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0948520-c5e4-47ee-8577-c3ff0af557ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- CBAM Block Definition -----------------\n",
    "def cbam_block(inputs, reduction_ratio=0.5):\n",
    "    channels = inputs.shape[-1]\n",
    "\n",
    "    # Channel Attention\n",
    "    avg_pool = layers.GlobalAveragePooling2D()(inputs)\n",
    "    max_pool = layers.GlobalMaxPooling2D()(inputs)\n",
    "    shared_layer_1 = layers.Dense(int(channels * reduction_ratio), activation='relu', use_bias=True)\n",
    "    shared_layer_2 = layers.Dense(channels, activation='relu', use_bias=True)\n",
    "\n",
    "    avg_pool = shared_layer_1(avg_pool)\n",
    "    avg_pool = shared_layer_2(avg_pool)\n",
    "    max_pool = shared_layer_1(max_pool)\n",
    "    max_pool = shared_layer_2(max_pool)\n",
    "\n",
    "    attention = layers.Add()([avg_pool, max_pool])\n",
    "    attention = layers.Activation('sigmoid')(attention)\n",
    "    attention = layers.Reshape((1, 1, channels))(attention)\n",
    "    scaled_inputs = layers.Multiply()([inputs, attention])\n",
    "\n",
    "    # Spatial Attention\n",
    "    squeeze = layers.Conv2D(filters=1, kernel_size=1, activation='sigmoid', use_bias=False)(scaled_inputs)\n",
    "    expanded_inputs = layers.Multiply()([scaled_inputs, squeeze])\n",
    "\n",
    "    return expanded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "523bf441-0742-4ebd-a506-e715028a7f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18_CBAM_Model():\n",
    "    input_shape = (224, 224, 3)\n",
    "    resnet18 = tf.keras.applications.ResNet50(\n",
    "        include_top=False, \n",
    "        input_shape=input_shape, \n",
    "        weights='imagenet'\n",
    "    )  # Note: Manually adapt to ResNet18 if needed.\n",
    "\n",
    "    x = cbam_block(resnet18.output)  # Apply CBAM block\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(units=1024, activation='relu')(x)\n",
    "    x = layers.Dense(units=512, activation='relu')(x)\n",
    "    x = layers.Dense(units=256, activation='relu')(x)\n",
    "    x = layers.Dense(units=128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.Dense(units=4, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs=resnet18.input, outputs=x, name='ResNet18_CBAM_Model')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a90219f-98da-4b91-8ba1-769e12d5e4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Compile and Train -----------------\n",
    "def compile_and_train(model, train_data, test_data, epochs=10, learning_rate=0.001):\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        validation_data=test_data,\n",
    "        epochs=epochs,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f66a113-6bb9-45b9-afe7-4d4f2481946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_global_model(model, test_loader, client_idx, output_dir=\"resNet18_model_results\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Ensure the output directory exists\n",
    "    output_file = os.path.join(output_dir, f\"Model_Results_Client_{client_idx + 1}.txt\")\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0\n",
    "\n",
    "    for features, labels in test_loader:\n",
    "        features_tf = tf.convert_to_tensor(features, dtype=tf.float32)\n",
    "\n",
    "        # Convert one-hot encoded labels to class indices\n",
    "        if len(labels.shape) > 1 and labels.shape[-1] > 1:  # Likely one-hot\n",
    "            labels_tf = tf.argmax(labels, axis=1, output_type=tf.int32)\n",
    "        else:\n",
    "            labels_tf = tf.convert_to_tensor(labels, dtype=tf.int32)\n",
    "\n",
    "        # Debugging: Print shapes\n",
    "        print(f\"Features shape: {features_tf.shape}, Labels shape: {labels_tf.shape}\")\n",
    "\n",
    "        # Get predictions\n",
    "        predictions = model(features_tf, training=False)\n",
    "        predicted = tf.argmax(predictions, axis=1, output_type=tf.int32)\n",
    "\n",
    "        # Accumulate predictions and labels\n",
    "        all_preds.extend(predicted.numpy())\n",
    "        all_labels.extend(labels_tf.numpy())\n",
    "\n",
    "\n",
    "        # Compute loss\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels_tf, logits=predictions)\n",
    "        total_loss += tf.reduce_mean(loss).numpy()\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # Classification report\n",
    "    class_names = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"] \n",
    "    classification_report_str = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "\n",
    "    # Append metrics to a file\n",
    "    with open(output_file, \"w\") as file:\n",
    "        file.write(f\"Evaluation Metrics for Client {client_idx + 1}:\\n\")\n",
    "        file.write(f\"Accuracy: {accuracy * 100:.2f}%\\n\")\n",
    "        file.write(f\"Loss: {total_loss / len(test_loader):.4f}\\n\")\n",
    "        file.write(f\"Precision: {precision:.4f}\\n\")\n",
    "        file.write(f\"Recall: {recall:.4f}\\n\")\n",
    "        file.write(f\"F1 Score: {f1:.4f}\\n\\n\")\n",
    "        file.write(\"Classification Report:\\n\")\n",
    "        file.write(classification_report_str)\n",
    "        file.write(\"\\nConfusion Matrix:\\n\")\n",
    "        file.write(\"\\n\".join([\"\\t\".join(map(str, row)) for row in conf_matrix]))\n",
    "        file.write(\"\\n\" + \"-\" * 50 + \"\\n\")\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"\\nClassification Report:\\n\", classification_report_str)\n",
    "    print(f\"\\nAccuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Loss: {total_loss / len(test_loader):.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Plot and save heatmap\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title(f'Confusion Matrix (Client {client_idx + 1})')\n",
    "    plt.savefig(os.path.join(output_dir, f\"confusion_matrix_Client_{client_idx + 1}.png\"))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00027c34-21eb-479b-b3ce-9c6d642ee428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories for each client\n",
    "split_dirs = [\n",
    "    \"../NON_IID/Model_1\",\n",
    "    \"../NON_IID/Model_2\",\n",
    "    \"../NON_IID/Model_3\",\n",
    "    \"../NON_IID/Model_4\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e5cfb57-03f1-4b37-b3b7-164be193e456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 image sizes: torch.Size([25, 224, 224, 3])\n"
     ]
    }
   ],
   "source": [
    "# Updated image transformations: Normalize first, then permute\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),          # Convert image to tensor format (C, H, W)\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize\n",
    "    transforms.Lambda(lambda x: x.permute(1, 2, 0))  # Permute to (H, W, C)\n",
    "])\n",
    "\n",
    "def get_tumor_dataloaders(split_dirs, batch_size=25, shuffle=True):\n",
    "    \"\"\"\n",
    "    Returns data loaders for all clients for both training and testing sets.\n",
    "    \"\"\"\n",
    "    tumor_iid_train_dls = []\n",
    "    tumor_iid_test_dls = []\n",
    "\n",
    "    for client_idx, client_dir in enumerate(split_dirs):\n",
    "        # Get the directory for the current client\n",
    "        train_dir = os.path.join(client_dir, 'train')\n",
    "        test_dir = os.path.join(client_dir, 'test')\n",
    "\n",
    "        # Check if the directories exist\n",
    "        if not os.path.exists(train_dir) or not os.path.exists(test_dir):\n",
    "            print(f\"Directory not found for client {client_idx + 1}:\")\n",
    "            print(f\"Train dir: {train_dir}\")\n",
    "            print(f\"Test dir: {test_dir}\")\n",
    "            continue\n",
    "\n",
    "        # Load training data for the current client\n",
    "        train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "        # Load testing data for the current client\n",
    "        test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Append the dataloaders for the current client to the list\n",
    "        tumor_iid_train_dls.append(train_loader)\n",
    "        tumor_iid_test_dls.append(test_loader)\n",
    "\n",
    "    return tumor_iid_train_dls, tumor_iid_test_dls\n",
    "\n",
    "# Get the training and testing data loaders\n",
    "Tumor_iid_train_dls, Tumor_iid_test_dls = get_tumor_dataloaders(split_dirs, batch_size=25)\n",
    "\n",
    "# Checking the sizes of the images in the data loaders to verify the shape\n",
    "for batch_idx, (images, labels) in enumerate(Tumor_iid_train_dls[0]):  # Checking for client 1\n",
    "    print(f\"Batch {batch_idx} image sizes: {images.size()}\")  # Should print torch.Size([25, 224, 224, 3])\n",
    "    break  # Check only the first batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0760658e-bfe7-45d6-a000-51957d96ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def pytorch_to_tf_dataset(pytorch_loader, num_classes):\n",
    "    \"\"\"\n",
    "    Converts a PyTorch DataLoader to a TensorFlow dataset with one-hot encoded labels.\n",
    "    \"\"\"\n",
    "    images, labels = [], []\n",
    "    for batch_images, batch_labels in pytorch_loader:\n",
    "        # Convert PyTorch tensors to NumPy arrays and permute to (Batch, Height, Width, Channels)\n",
    "        images.append(batch_images.permute(0, 2, 1, 3).numpy())\n",
    "        # One-hot encode labels\n",
    "        labels.append(to_categorical(batch_labels.numpy(), num_classes=num_classes))\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    images = np.concatenate(images, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    \n",
    "    # Create TensorFlow dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    return dataset.batch(pytorch_loader.batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18f99030-9b20-4e4f-ae52-5a05e576e1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and testing on dataset: Model_1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 13:51:15.084362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31132 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 8s 0us/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 13:51:34.453491: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [1321,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-12-04 13:51:50.513682: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n",
      "2024-12-04 13:51:51.940252: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x11983a50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-04 13:51:51.940295: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-12-04 13:51:51.946074: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-04 13:51:52.103490: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - ETA: 0s - loss: 0.5001 - accuracy: 0.7986"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 13:52:36.085040: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [342,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 66s 421ms/step - loss: 0.5001 - accuracy: 0.7986 - val_loss: 2.4287 - val_accuracy: 0.6170\n",
      "Epoch 2/10\n",
      "53/53 [==============================] - 16s 312ms/step - loss: 0.1943 - accuracy: 0.9326 - val_loss: 1.7837 - val_accuracy: 0.6199\n",
      "Epoch 3/10\n",
      "53/53 [==============================] - 16s 305ms/step - loss: 0.1060 - accuracy: 0.9644 - val_loss: 4.4964 - val_accuracy: 0.6287\n",
      "Epoch 4/10\n",
      "53/53 [==============================] - 16s 306ms/step - loss: 0.0787 - accuracy: 0.9758 - val_loss: 3.8226 - val_accuracy: 0.6287\n",
      "Epoch 5/10\n",
      "53/53 [==============================] - 16s 307ms/step - loss: 0.0598 - accuracy: 0.9841 - val_loss: 5.3279 - val_accuracy: 0.6257\n",
      "Epoch 6/10\n",
      "53/53 [==============================] - 16s 309ms/step - loss: 0.0390 - accuracy: 0.9886 - val_loss: 1.1769 - val_accuracy: 0.7018\n",
      "Epoch 7/10\n",
      "53/53 [==============================] - 16s 305ms/step - loss: 0.0684 - accuracy: 0.9826 - val_loss: 1.3329 - val_accuracy: 0.6784\n",
      "Epoch 8/10\n",
      "53/53 [==============================] - 16s 305ms/step - loss: 0.0376 - accuracy: 0.9917 - val_loss: 1.5681 - val_accuracy: 0.7105\n",
      "Epoch 9/10\n",
      "53/53 [==============================] - 16s 306ms/step - loss: 0.0477 - accuracy: 0.9886 - val_loss: 7.8892 - val_accuracy: 0.6228\n",
      "Epoch 10/10\n",
      "53/53 [==============================] - 16s 306ms/step - loss: 0.0229 - accuracy: 0.9962 - val_loss: 1.8164 - val_accuracy: 0.7047\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (17, 224, 224, 3), Labels shape: (17,)\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.68      1.00      0.81       210\n",
      "  meningioma       0.88      0.22      0.35        32\n",
      "     notumor       1.00      0.44      0.61        50\n",
      "   pituitary       0.40      0.04      0.07        50\n",
      "\n",
      "    accuracy                           0.70       342\n",
      "   macro avg       0.74      0.42      0.46       342\n",
      "weighted avg       0.71      0.70      0.63       342\n",
      "\n",
      "\n",
      "Accuracy: 70.47%\n",
      "Loss: 1.0412\n",
      "Precision: 0.7066\n",
      "Recall: 0.7047\n",
      "F1 Score: 0.6316\n",
      "Training and evaluation completed for Model_1\n",
      "\n",
      "\n",
      "Training and testing on dataset: Model_2\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 13:55:27.746921: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [1339,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - ETA: 0s - loss: 0.5875 - accuracy: 0.7633"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 13:56:26.891368: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [340,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 62s 396ms/step - loss: 0.5875 - accuracy: 0.7633 - val_loss: 1.1381 - val_accuracy: 0.6176\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 16s 303ms/step - loss: 0.1988 - accuracy: 0.9425 - val_loss: 1.7259 - val_accuracy: 0.2206\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 16s 304ms/step - loss: 0.0834 - accuracy: 0.9739 - val_loss: 2.2811 - val_accuracy: 0.1824\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 16s 304ms/step - loss: 0.0718 - accuracy: 0.9798 - val_loss: 1.5513 - val_accuracy: 0.4147\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 16s 304ms/step - loss: 0.0262 - accuracy: 0.9918 - val_loss: 2.4370 - val_accuracy: 0.2294\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 17s 307ms/step - loss: 0.0535 - accuracy: 0.9836 - val_loss: 1.4993 - val_accuracy: 0.4618\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (15, 224, 224, 3), Labels shape: (15,)\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.00      0.00      0.00        30\n",
      "  meningioma       0.62      1.00      0.76       210\n",
      "     notumor       0.00      0.00      0.00        50\n",
      "   pituitary       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.62       340\n",
      "   macro avg       0.15      0.25      0.19       340\n",
      "weighted avg       0.38      0.62      0.47       340\n",
      "\n",
      "\n",
      "Accuracy: 61.76%\n",
      "Loss: 1.2082\n",
      "Precision: 0.3815\n",
      "Recall: 0.6176\n",
      "F1 Score: 0.4717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/ml_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/envs/ml_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/envs/ml_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/envs/ml_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluation completed for Model_2\n",
      "\n",
      "\n",
      "Training and testing on dataset: Model_3\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 13:58:11.594155: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [1595,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - ETA: 0s - loss: 0.3974 - accuracy: 0.8050"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 13:59:10.928556: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [367,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 62s 372ms/step - loss: 0.3974 - accuracy: 0.8050 - val_loss: 1.6834 - val_accuracy: 0.6948\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 19s 305ms/step - loss: 0.2806 - accuracy: 0.8740 - val_loss: 2.8379 - val_accuracy: 0.6948\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 19s 302ms/step - loss: 0.2089 - accuracy: 0.9047 - val_loss: 3.1508 - val_accuracy: 0.6948\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 19s 304ms/step - loss: 0.1598 - accuracy: 0.9342 - val_loss: 5.9495 - val_accuracy: 0.6948\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 19s 304ms/step - loss: 0.0885 - accuracy: 0.9661 - val_loss: 3.8256 - val_accuracy: 0.6948\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 20s 307ms/step - loss: 0.0320 - accuracy: 0.9893 - val_loss: 10.4311 - val_accuracy: 0.6948\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (17, 224, 224, 3), Labels shape: (17,)\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.00      0.00      0.00        30\n",
      "  meningioma       0.00      0.00      0.00        32\n",
      "     notumor       0.69      1.00      0.82       255\n",
      "   pituitary       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.69       367\n",
      "   macro avg       0.17      0.25      0.20       367\n",
      "weighted avg       0.48      0.69      0.57       367\n",
      "\n",
      "\n",
      "Accuracy: 69.48%\n",
      "Loss: 1.0639\n",
      "Precision: 0.4828\n",
      "Recall: 0.6948\n",
      "F1 Score: 0.5697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/ml_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/envs/ml_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/envs/ml_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/envs/ml_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluation completed for Model_3\n",
      "\n",
      "\n",
      "Training and testing on dataset: Model_4\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 14:01:13.731093: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [1457,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - ETA: 0s - loss: 0.4681 - accuracy: 0.8092"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 14:02:09.584105: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [262,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 59s 368ms/step - loss: 0.4681 - accuracy: 0.8092 - val_loss: 1.3829 - val_accuracy: 0.1908\n",
      "Epoch 2/10\n",
      "59/59 [==============================] - 17s 296ms/step - loss: 0.1625 - accuracy: 0.9403 - val_loss: 1.7248 - val_accuracy: 0.1336\n",
      "Epoch 3/10\n",
      "59/59 [==============================] - 18s 299ms/step - loss: 0.0854 - accuracy: 0.9725 - val_loss: 1.3650 - val_accuracy: 0.3053\n",
      "Epoch 4/10\n",
      "59/59 [==============================] - 17s 297ms/step - loss: 0.1035 - accuracy: 0.9705 - val_loss: 2.1906 - val_accuracy: 0.1832\n",
      "Epoch 5/10\n",
      "59/59 [==============================] - 17s 296ms/step - loss: 0.0473 - accuracy: 0.9876 - val_loss: 1.8952 - val_accuracy: 0.2176\n",
      "Epoch 6/10\n",
      "59/59 [==============================] - 17s 297ms/step - loss: 0.0277 - accuracy: 0.9925 - val_loss: 3.0268 - val_accuracy: 0.1641\n",
      "Epoch 7/10\n",
      "59/59 [==============================] - 18s 299ms/step - loss: 0.0510 - accuracy: 0.9911 - val_loss: 1.3279 - val_accuracy: 0.3740\n",
      "Epoch 8/10\n",
      "59/59 [==============================] - 18s 298ms/step - loss: 0.0125 - accuracy: 0.9966 - val_loss: 4.0993 - val_accuracy: 0.1718\n",
      "Epoch 9/10\n",
      "59/59 [==============================] - 18s 300ms/step - loss: 0.0348 - accuracy: 0.9904 - val_loss: 0.9661 - val_accuracy: 0.7137\n",
      "Epoch 10/10\n",
      "59/59 [==============================] - 18s 300ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8689 - val_accuracy: 0.7672\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (12, 224, 224, 3), Labels shape: (12,)\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.40      0.97      0.56        30\n",
      "  meningioma       0.90      0.28      0.43        32\n",
      "     notumor       1.00      0.48      0.65        50\n",
      "   pituitary       0.90      0.93      0.91       150\n",
      "\n",
      "    accuracy                           0.77       262\n",
      "   macro avg       0.80      0.66      0.64       262\n",
      "weighted avg       0.86      0.77      0.76       262\n",
      "\n",
      "\n",
      "Accuracy: 76.72%\n",
      "Loss: 0.9549\n",
      "Precision: 0.8597\n",
      "Recall: 0.7672\n",
      "F1 Score: 0.7624\n",
      "Training and evaluation completed for Model_4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Iterate over all client datasets\n",
    "    for client_idx in range(len(split_dirs)):\n",
    "        print(f\"\\nTraining and testing on dataset: Model_{client_idx + 1}\\n\")\n",
    "        \n",
    "        # Load data for the current client\n",
    "        train_loader = Tumor_iid_train_dls[client_idx]\n",
    "        test_loader = Tumor_iid_test_dls[client_idx]\n",
    "\n",
    "        # Number of classes in your dataset\n",
    "        num_classes = 4\n",
    "\n",
    "        # Convert PyTorch DataLoaders to TensorFlow datasets\n",
    "        tf_train_dataset = pytorch_to_tf_dataset(train_loader, num_classes)\n",
    "        tf_test_dataset = pytorch_to_tf_dataset(test_loader, num_classes)\n",
    "\n",
    "        # Build Model\n",
    "        model = ResNet18_CBAM_Model()\n",
    "\n",
    "        # Use these datasets for training\n",
    "        history = compile_and_train(model, tf_train_dataset, tf_test_dataset, epochs=10, learning_rate=0.0001)\n",
    "\n",
    "        # Evaluate and Save Results\n",
    "        evaluate_global_model(model, tf_test_dataset, client_idx, output_dir=\"resNet18_model_results\")\n",
    "\n",
    "        print(f\"Training and evaluation completed for Model_{client_idx + 1}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62dcb5c-3847-49f5-b4af-4c0049bb85b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
