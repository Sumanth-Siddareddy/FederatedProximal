{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47e59dad-4788-4731-a16c-640008f22339",
   "metadata": {},
   "source": [
    "# FedAvg mu=0\n",
    "# fedavg start at 11:30 ends at 2:00 - 2(1/2) hrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4624b5c5-9208-4255-b733-0a22b7f9e322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 17:32:10.166799: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-04 17:32:11.337143: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# ----------------- Import Libraries -----------------\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Input, BatchNormalization, Dense, Activation, Dropout\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score, classification_report\n",
    "\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b348eb7e-f929-4200-925d-862eb32d4cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- CBAM Block Definition -----------------\n",
    "def cbam_block(inputs, reduction_ratio=0.5):\n",
    "    channels = inputs.shape[-1]\n",
    "\n",
    "    # Channel Attention\n",
    "    avg_pool = layers.GlobalAveragePooling2D()(inputs)\n",
    "    max_pool = layers.GlobalMaxPooling2D()(inputs)\n",
    "    shared_layer_1 = layers.Dense(int(channels * reduction_ratio), activation='relu', use_bias=True)\n",
    "    shared_layer_2 = layers.Dense(channels, activation='relu', use_bias=True)\n",
    "\n",
    "    avg_pool = shared_layer_1(avg_pool)\n",
    "    avg_pool = shared_layer_2(avg_pool)\n",
    "    max_pool = shared_layer_1(max_pool)\n",
    "    max_pool = shared_layer_2(max_pool)\n",
    "\n",
    "    attention = layers.Add()([avg_pool, max_pool])\n",
    "    attention = layers.Activation('sigmoid')(attention)\n",
    "    attention = layers.Reshape((1, 1, channels))(attention)\n",
    "    scaled_inputs = layers.Multiply()([inputs, attention])\n",
    "\n",
    "    # Spatial Attention\n",
    "    squeeze = layers.Conv2D(filters=1, kernel_size=1, activation='sigmoid', use_bias=False)(scaled_inputs)\n",
    "    expanded_inputs = layers.Multiply()([scaled_inputs, squeeze])\n",
    "\n",
    "    return expanded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fc0ceaf-b4c6-495f-ab85-189769f17cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG19_CBAM_Model():\n",
    "    input_shape = (224, 224, 3)\n",
    "    vgg19 = tf.keras.applications.VGG19(include_top=False, input_shape=input_shape, weights='imagenet')\n",
    "\n",
    "    x = cbam_block(vgg19.output)  # Apply CBAM block\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(units=1024, activation='relu')(x)\n",
    "    x = layers.Dense(units=512, activation='relu')(x)\n",
    "    x = layers.Dense(units=256, activation='relu')(x)\n",
    "    x = layers.Dense(units=128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.Dense(units=4, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs=vgg19.input, outputs=x, name='VGG19_CBAM_Model')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b3669e1-45c6-4af2-8b2d-d991072c9c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 17:32:16.939481: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31132 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80134624/80134624 [==============================] - 6s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = VGG19_CBAM_Model()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb3eee42-212c-43c4-bb02-9c7fe29bd470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_classifier(predictions, labels):\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=predictions)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "def loss_dataset(model, dataset, loss_f):\n",
    "    loss = 0\n",
    "    for idx, (features, labels) in enumerate(dataset):\n",
    "        # Convert PyTorch tensors to NumPy and then to TensorFlow tensors\n",
    "        features_np = features.detach().cpu().numpy()\n",
    "        labels_np = labels.detach().cpu().numpy()\n",
    "\n",
    "        features_tf = tf.convert_to_tensor(features_np, dtype=tf.float32)\n",
    "        labels_tf = tf.convert_to_tensor(labels_np, dtype=tf.int32)\n",
    "\n",
    "        predictions = model(features_tf)\n",
    "        loss += loss_f(predictions, labels_tf)\n",
    "    loss /= (idx + 1)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def accuracy_dataset(model, dataset):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for features, labels in dataset:\n",
    "        # Convert PyTorch tensors to NumPy and then to TensorFlow tensors\n",
    "        features_np = features.detach().cpu().numpy()\n",
    "        labels_np = labels.detach().cpu().numpy()\n",
    "\n",
    "        features_tf = tf.convert_to_tensor(features_np, dtype=tf.float32)\n",
    "        labels_tf = tf.convert_to_tensor(labels_np, dtype=tf.int32)\n",
    "\n",
    "        predictions = model(features_tf)\n",
    "        predicted = tf.argmax(predictions, axis=1, output_type=tf.int32)\n",
    "        correct += tf.reduce_sum(tf.cast(tf.equal(predicted, labels_tf), tf.int32)).numpy()\n",
    "        total += labels_tf.shape[0]\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def train_step(model, model_0, mu, optimizer, train_data, loss_f):\n",
    "    total_loss = 0\n",
    "    for idx, (features, labels) in enumerate(train_data):\n",
    "        # Convert PyTorch tensors to NumPy and then to TensorFlow tensors\n",
    "        features_np = features.detach().cpu().numpy()\n",
    "        labels_np = labels.detach().cpu().numpy()\n",
    "\n",
    "        features_tf = tf.convert_to_tensor(features_np, dtype=tf.float32)\n",
    "        labels_tf = tf.convert_to_tensor(labels_np, dtype=tf.int32)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(features_tf)\n",
    "            loss = loss_f(predictions, labels_tf)\n",
    "            loss += mu / 2 * difference_models_norm_2(model, model_0)\n",
    "\n",
    "        total_loss += loss\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return total_loss / (idx + 1)\n",
    "\n",
    "\n",
    "def local_learning(model, mu, optimizer, train_data, epochs, loss_f):\n",
    "    # Clone the model instead of using deepcopy\n",
    "    model_0 = tf.keras.models.clone_model(model)\n",
    "    model_0.set_weights(model.get_weights())  # Set weights to be identical initially\n",
    "\n",
    "    for e in range(epochs):\n",
    "        local_loss = train_step(model, model_0, mu, optimizer, train_data, loss_f)\n",
    "\n",
    "    return local_loss\n",
    "\n",
    "\n",
    "def difference_models_norm_2(model_1, model_2):\n",
    "    norm = tf.reduce_sum([tf.reduce_sum(tf.square(w1 - w2)) for w1, w2 in zip(model_1.trainable_variables, model_2.trainable_variables)])\n",
    "    return norm\n",
    "\n",
    "def set_to_zero_model_weights(model):\n",
    "    for layer_weights in model.trainable_variables:\n",
    "        layer_weights.assign(tf.zeros_like(layer_weights))\n",
    "\n",
    "def average_models(model, clients_models_hist, weights):\n",
    "    set_to_zero_model_weights(model)\n",
    "    for k, client_hist in enumerate(clients_models_hist):\n",
    "        for idx, layer_weights in enumerate(model.trainable_variables):\n",
    "            contribution = client_hist[idx] * weights[k]\n",
    "            layer_weights.assign_add(contribution)\n",
    "\n",
    "#_______________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8b5fa67-f93d-4ece-bdd6-a7cb178879ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FedProx(model, training_sets, n_iter, testing_sets, mu=0, epochs=5, lr=0.01, decay=1):\n",
    "    # Verify that `model` is a Keras model instance\n",
    "    if not isinstance(model, tf.keras.Model):\n",
    "        raise TypeError(\"The provided model is not a TensorFlow Keras model. Please provide a valid Keras model.\")\n",
    "\n",
    "    loss_f = loss_classifier\n",
    "    K = len(training_sets)\n",
    "    n_samples = sum([len(db) for db in training_sets])\n",
    "    weights = [len(db) / n_samples for db in training_sets]\n",
    "    print(\"Clients' weights:\", weights)\n",
    "\n",
    "    # Initialize history lists for training and testing\n",
    "    train_loss_hist = []\n",
    "    train_acc_hist = []\n",
    "    test_loss_hist = []\n",
    "    test_acc_hist = []\n",
    "    models_hist = []\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        clients_params = []\n",
    "        clients_losses = []\n",
    "        clients_accuracies = []\n",
    "\n",
    "        for k in range(K):\n",
    "            # Clone the model and set weights for local training\n",
    "            local_model = tf.keras.models.clone_model(model)\n",
    "            local_model.set_weights(model.get_weights())\n",
    "\n",
    "            local_optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "\n",
    "            # Perform local training and track the loss\n",
    "            local_loss = local_learning(local_model, mu, local_optimizer, training_sets[k], epochs, loss_f)\n",
    "            clients_losses.append(local_loss)\n",
    "\n",
    "            # Track training accuracy for the client\n",
    "            train_acc = accuracy_dataset(local_model, training_sets[k])\n",
    "            clients_accuracies.append(train_acc)\n",
    "\n",
    "            # Store model parameters (deep copy to ensure immutability)\n",
    "            clients_params.append([tf.identity(tens_param) for tens_param in local_model.trainable_variables])\n",
    "\n",
    "        # Average the local models into the global model\n",
    "        average_models(model, clients_params, weights=weights)\n",
    "        models_hist.append(deepcopy(clients_params))\n",
    "\n",
    "        # Collect metrics for this iteration\n",
    "        train_loss_hist.append(clients_losses)\n",
    "        train_acc_hist.append(clients_accuracies)\n",
    "\n",
    "        # Compute testing metrics using the global model\n",
    "        test_loss_hist.append([loss_dataset(model, dl, loss_f).numpy() for dl in testing_sets])\n",
    "        test_acc_hist.append([accuracy_dataset(model, dl) for dl in testing_sets])\n",
    "\n",
    "        # Update learning rate by decay factor\n",
    "        lr *= decay\n",
    "        print(f'====> i: {i+1} Server Test Accuracy: {test_acc_hist[-1]}')\n",
    "\n",
    "    return model, train_loss_hist, train_acc_hist, test_loss_hist, test_acc_hist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95454d1e-3e27-4651-9743-9dffc4ad618c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 image sizes: torch.Size([25, 224, 224, 3])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Directories for each client\n",
    "split_dirs = [\n",
    "    \"Federated_Learning_NON_IID/Model_1\",\n",
    "    \"Federated_Learning_NON_IID/Model_2\",\n",
    "    \"Federated_Learning_NON_IID/Model_3\",\n",
    "    \"Federated_Learning_NON_IID/Model_4\"\n",
    "]\n",
    "\n",
    "# Number of clients\n",
    "n_clients = len(split_dirs)\n",
    "\n",
    "# Updated image transformations: Normalize first, then permute\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),          # Convert image to tensor format (C, H, W)\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize\n",
    "    transforms.Lambda(lambda x: x.permute(1, 2, 0))  # Permute to (H, W, C)\n",
    "])\n",
    "\n",
    "def get_tumor_dataloaders(split_dirs, batch_size=25, shuffle=True):\n",
    "    \"\"\"\n",
    "    Returns data loaders for all clients for both training and testing sets.\n",
    "    \"\"\"\n",
    "    tumor_iid_train_dls = []\n",
    "    tumor_iid_test_dls = []\n",
    "\n",
    "    for client_idx, client_dir in enumerate(split_dirs):\n",
    "        # Get the directory for the current client\n",
    "        train_dir = os.path.join(client_dir, 'train')\n",
    "        test_dir = os.path.join(client_dir, 'test')\n",
    "\n",
    "        # Check if the directories exist\n",
    "        if not os.path.exists(train_dir) or not os.path.exists(test_dir):\n",
    "            print(f\"Directory not found for client {client_idx + 1}:\")\n",
    "            print(f\"Train dir: {train_dir}\")\n",
    "            print(f\"Test dir: {test_dir}\")\n",
    "            continue\n",
    "\n",
    "        # Load training data for the current client\n",
    "        train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "        # Load testing data for the current client\n",
    "        test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Append the dataloaders for the current client to the list\n",
    "        tumor_iid_train_dls.append(train_loader)\n",
    "        tumor_iid_test_dls.append(test_loader)\n",
    "\n",
    "    return tumor_iid_train_dls, tumor_iid_test_dls\n",
    "\n",
    "# Get the training and testing data loaders\n",
    "Tumor_iid_train_dls, Tumor_iid_test_dls = get_tumor_dataloaders(split_dirs, batch_size=25)\n",
    "\n",
    "# Checking the sizes of the images in the data loaders to verify the shape\n",
    "for batch_idx, (images, labels) in enumerate(Tumor_iid_train_dls[0]):  # Checking for client 1\n",
    "    print(f\"Batch {batch_idx} image sizes: {images.size()}\")  # Should print torch.Size([25, 224, 224, 3])\n",
    "    break  # Check only the first batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3266a342-d9d7-472c-bc89-7c8ec2139be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clients' weights: [0.22620689655172413, 0.2303448275862069, 0.2868965517241379, 0.25655172413793104]\n",
      "====> i: 1 Server Test Accuracy: [25.0, 25.0, 25.0, 25.0]\n",
      "====> i: 2 Server Test Accuracy: [25.0, 25.0, 25.0, 25.0]\n",
      "====> i: 3 Server Test Accuracy: [25.0, 25.0, 25.0, 25.0]\n",
      "====> i: 4 Server Test Accuracy: [25.0, 25.0, 25.0, 25.0]\n",
      "====> i: 5 Server Test Accuracy: [25.0, 25.0, 25.0, 25.0]\n",
      "====> i: 6 Server Test Accuracy: [25.0, 25.0, 25.0, 25.0]\n",
      "====> i: 7 Server Test Accuracy: [25.0, 25.0, 25.0, 25.0]\n",
      "====> i: 8 Server Test Accuracy: [25.0, 25.0, 25.0, 25.0]\n",
      "====> i: 9 Server Test Accuracy: [25.0, 25.0, 25.0, 25.0]\n",
      "====> i: 10 Server Test Accuracy: [25.0, 25.0, 25.0, 25.0]\n"
     ]
    }
   ],
   "source": [
    "n_iter = 10\n",
    "# Execute FedProx with the new 4-client setup\n",
    "model, train_loss, train_acc, test_loss, test_acc = FedProx(\n",
    "    model, Tumor_iid_train_dls, n_iter, Tumor_iid_test_dls, mu=0.0, epochs=1, lr=0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e73bf38-4a45-4a45-8d4e-0d8468530000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, classification_report\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),          # Convert image to tensor format (C, H, W)\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize\n",
    "    transforms.Lambda(lambda x: x.permute(1, 2, 0))  # Permute to (H, W, C)\n",
    "])\n",
    "\n",
    "# Load the testing dataset\n",
    "test_dir = 'BrainTumor_MRI/Testing'\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Class names mapping (adjust if necessary)\n",
    "class_names = test_dataset.classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bcf8f4e-f7b4-49dd-8124-3e97b062f13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the global model on the testing dataset\n",
    "def evaluate_global_model(model, test_loader):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0\n",
    "\n",
    "    for features, labels in test_loader:\n",
    "        # Convert to TensorFlow tensors\n",
    "        features_np = features.detach().cpu().numpy()\n",
    "        labels_np = labels.detach().cpu().numpy()\n",
    "\n",
    "        features_tf = tf.convert_to_tensor(features_np, dtype=tf.float32)\n",
    "        labels_tf = tf.convert_to_tensor(labels_np, dtype=tf.int32)\n",
    "\n",
    "        # Get predictions\n",
    "        predictions = model(features_tf)\n",
    "        predicted = tf.argmax(predictions, axis=1, output_type=tf.int32)\n",
    "\n",
    "        # Accumulate predictions and labels\n",
    "        all_preds.extend(predicted.numpy())\n",
    "        all_labels.extend(labels_np)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels_tf, logits=predictions)\n",
    "        total_loss += tf.reduce_mean(loss).numpy()\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    print(f\"\\nConfusion Matrix:\\n{conf_matrix}\")\n",
    "    print(f\"\\nAccuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Loss: {total_loss / len(test_loader):.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "    # Print detailed classification report\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72ec1391-1063-4a27-aab6-89f033280feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[300   0   0   0]\n",
      " [305   0   0   1]\n",
      " [400   0   0   5]\n",
      " [300   0   0   0]]\n",
      "\n",
      "Accuracy: 22.88%\n",
      "Loss: 1.3863\n",
      "Precision: 0.0526\n",
      "Recall: 0.2288\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.23      1.00      0.37       300\n",
      "  meningioma       0.00      0.00      0.00       306\n",
      "     notumor       0.00      0.00      0.00       405\n",
      "   pituitary       0.00      0.00      0.00       300\n",
      "\n",
      "    accuracy                           0.23      1311\n",
      "   macro avg       0.06      0.25      0.09      1311\n",
      "weighted avg       0.05      0.23      0.09      1311\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/ml_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/envs/ml_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/envs/ml_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/envs/ml_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the testing dataset\n",
    "evaluate_global_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "324fc9ae-2238-4822-9c46-665cd1c43d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_acc_loss(title: str, train_loss_hist: list, train_acc_hist: list,\n",
    "                  test_loss_hist: list, test_acc_hist: list):\n",
    "    plt.figure(figsize=(15, 5))  # Make the plot wider\n",
    "\n",
    "    # Plot training loss\n",
    "    plt.subplot(2, 2, 1)\n",
    "    lines = plt.plot(train_loss_hist)\n",
    "    plt.title(\"Training Loss\")\n",
    "    plt.legend(lines, [f\"C{i+1}\" for i in range(len(train_loss_hist[0]))])\n",
    "\n",
    "    # Plot training accuracy\n",
    "    plt.subplot(2, 2, 2)\n",
    "    lines = plt.plot(train_acc_hist)\n",
    "    plt.title(\"Training Accuracy\")\n",
    "    plt.legend(lines, [f\"C{i+1}\" for i in range(len(train_acc_hist[0]))])\n",
    "\n",
    "    # Plot testing loss\n",
    "    plt.subplot(2, 2, 3)\n",
    "    lines = plt.plot(test_loss_hist)\n",
    "    plt.title(\"Testing Loss\")\n",
    "    plt.legend(lines, [f\"C{i+1}\" for i in range(len(test_loss_hist[0]))])\n",
    "\n",
    "    # Plot testing accuracy\n",
    "    plt.subplot(2, 2, 4)\n",
    "    lines = plt.plot(test_acc_hist)\n",
    "    plt.title(\"Testing Accuracy\")\n",
    "    plt.legend(lines, [f\"C{i+1}\" for i in range(len(test_acc_hist[0]))])\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def save_history_to_file(filename, n_iter, train_loss_hist, train_acc_hist,\n",
    "                         test_loss_hist, test_acc_hist):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"FedProx Training Results\\n\")\n",
    "        f.write(\"=\"*50 + \"\\n\")\n",
    "        f.write(f\"Number of iterations: {n_iter}\\n\\n\")\n",
    "\n",
    "        # Write the history for each iteration\n",
    "        for i in range(n_iter):\n",
    "            f.write(f\"Iteration {i+1}:\\n\")\n",
    "            f.write(f\"Train Loss: {train_loss_hist[i]}\\n\")\n",
    "            f.write(f\"Train Accuracy: {train_acc_hist[i]}\\n\")\n",
    "            f.write(f\"Test Loss: {test_loss_hist[i]}\\n\")\n",
    "            f.write(f\"Test Accuracy: {test_acc_hist[i]}\\n\")\n",
    "            f.write(\"-\"*50 + \"\\n\")\n",
    "\n",
    "    print(f\"Training history saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "676d3332-aac0-4423-b622-629153fd1f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training history saved to FedAvg_VGG19.txt\n"
     ]
    }
   ],
   "source": [
    "# File to save the results\n",
    "output_file = \"FedAvg_VGG19.txt\"\n",
    "# Save the history to a file\n",
    "save_history_to_file(output_file, n_iter, train_loss, train_acc, test_loss, test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0de80605-ec1e-4657-8a82-727c0b0c73a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG19_CBAM_Model()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "882d4bfc-1b37-4263-94e4-a7203a8667f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clients' weights: [0.22620689655172413, 0.2303448275862069, 0.2868965517241379, 0.25655172413793104]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m n_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Execute FedProx with the new 4-client setup\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model_f, train_loss_f, train_acc_f, test_loss_f, test_acc_f \u001b[38;5;241m=\u001b[39m \u001b[43mFedProx\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTumor_iid_train_dls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTumor_iid_test_dls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 32\u001b[0m, in \u001b[0;36mFedProx\u001b[0;34m(model, training_sets, n_iter, testing_sets, mu, epochs, lr, decay)\u001b[0m\n\u001b[1;32m     29\u001b[0m local_optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39mlr)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Perform local training and track the loss\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m local_loss \u001b[38;5;241m=\u001b[39m \u001b[43mlocal_learning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_sets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_f\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m clients_losses\u001b[38;5;241m.\u001b[39mappend(local_loss)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Track training accuracy for the client\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 70\u001b[0m, in \u001b[0;36mlocal_learning\u001b[0;34m(model, mu, optimizer, train_data, epochs, loss_f)\u001b[0m\n\u001b[1;32m     67\u001b[0m model_0\u001b[38;5;241m.\u001b[39mset_weights(model\u001b[38;5;241m.\u001b[39mget_weights())  \u001b[38;5;66;03m# Set weights to be identical initially\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 70\u001b[0m     local_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_f\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m local_loss\n",
      "Cell \u001b[0;32mIn[5], line 44\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, model_0, mu, optimizer, train_data, loss_f)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step\u001b[39m(model, model_0, mu, optimizer, train_data, loss_f):\n\u001b[1;32m     43\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (features, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_data):\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;66;03m# Convert PyTorch tensors to NumPy and then to TensorFlow tensors\u001b[39;00m\n\u001b[1;32m     46\u001b[0m         features_np \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     47\u001b[0m         labels_np \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.9/site-packages/torchvision/datasets/folder.py:231\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    229\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader(path)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 231\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.9/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.9/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.9/site-packages/torchvision/transforms/functional.py:172\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    170\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mview(pic\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m1\u001b[39m], pic\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m0\u001b[39m], F_pil\u001b[38;5;241m.\u001b[39mget_image_num_channels(pic))\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mdefault_float_dtype)\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;241m255\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_iter = 10\n",
    "# Execute FedProx with the new 4-client setup\n",
    "model_f, train_loss_f, train_acc_f, test_loss_f, test_acc_f = FedProx(\n",
    "    model, Tumor_iid_train_dls, n_iter, Tumor_iid_test_dls, mu=0.4, epochs=1, lr=0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c18220a-bd12-41f2-a5df-d5d797cd84e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File to save the results\n",
    "output_file = \"FedProxmu=0.4_VGG19.txt\"\n",
    "# Save the history to a file\n",
    "save_history_to_file(output_file, n_iter, train_loss_f, train_acc_f, test_loss_f, test_acc_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80577bb-5c53-46a4-b64a-b1ebdfff22ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_loss_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efee654-d647-4cf4-8be3-8666214836b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_acc_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34da1e1d-0726-45d7-aefc-8f949e96bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( test_loss_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3b733b-f332-4bd3-b39c-76f6e5b589f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_acc_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb37d11a-46a9-46c5-84d9-5ee12372e0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_global_model(model_f, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f82f0c-3817-4cc4-9559-d7ab362410b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
