{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21c11376-9abd-43ab-855e-b6132588954d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 14:08:52.736494: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-04 14:08:53.835157: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# ----------------- Import Libraries -----------------\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score, classification_report\n",
    "\n",
    "import seaborn as sns\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e6b1542-3fa4-4d10-8f74-4d5c414360ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- CBAM Block Definition -----------------\n",
    "def cbam_block(inputs, reduction_ratio=0.5):\n",
    "    channels = inputs.shape[-1]\n",
    "\n",
    "    # Channel Attention\n",
    "    avg_pool = layers.GlobalAveragePooling2D()(inputs)\n",
    "    max_pool = layers.GlobalMaxPooling2D()(inputs)\n",
    "    shared_layer_1 = layers.Dense(int(channels * reduction_ratio), activation='relu', use_bias=True)\n",
    "    shared_layer_2 = layers.Dense(channels, activation='relu', use_bias=True)\n",
    "\n",
    "    avg_pool = shared_layer_1(avg_pool)\n",
    "    avg_pool = shared_layer_2(avg_pool)\n",
    "    max_pool = shared_layer_1(max_pool)\n",
    "    max_pool = shared_layer_2(max_pool)\n",
    "\n",
    "    attention = layers.Add()([avg_pool, max_pool])\n",
    "    attention = layers.Activation('sigmoid')(attention)\n",
    "    attention = layers.Reshape((1, 1, channels))(attention)\n",
    "    scaled_inputs = layers.Multiply()([inputs, attention])\n",
    "\n",
    "    # Spatial Attention\n",
    "    squeeze = layers.Conv2D(filters=1, kernel_size=1, activation='sigmoid', use_bias=False)(scaled_inputs)\n",
    "    expanded_inputs = layers.Multiply()([scaled_inputs, squeeze])\n",
    "\n",
    "    return expanded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e28747-b406-4a16-b735-c7c1512e4171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- ResNet50_CBAM_Model Definition -----------------\n",
    "def ResNet50_CBAM_Model():\n",
    "    input_shape = (224, 224, 3)\n",
    "    resnet50 = tf.keras.applications.ResNet50(include_top=False, input_shape=input_shape, weights='imagenet')\n",
    "\n",
    "    x = cbam_block(resnet50.output)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(units=1024, activation='relu')(x)\n",
    "    x = layers.Dense(units=512, activation='relu')(x)\n",
    "    x = layers.Dense(units=256, activation='relu')(x)\n",
    "    x = layers.Dense(units=128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.Dense(units=4, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs=resnet50.input, outputs=x, name='ResNet50_CBAM_Model')\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24989fab-abf2-451a-891a-e5af072bf41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Compile and Train -----------------\n",
    "def compile_and_train(model, train_data, test_data, epochs=10, learning_rate=0.001):\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        validation_data=test_data,\n",
    "        epochs=epochs,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab2a991-e6cc-41fe-8fff-09731233d144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Evaluate model performance -----------------\n",
    "def evaluate_global_model(model, test_loader, client_idx, output_dir=\"Reset50_model_results\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Ensure the output directory exists\n",
    "    output_file = os.path.join(output_dir, f\"Model_Results_Client_{client_idx + 1}.txt\")\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0\n",
    "\n",
    "    for features, labels in test_loader:\n",
    "        features_tf = tf.convert_to_tensor(features, dtype=tf.float32)\n",
    "\n",
    "        # Convert one-hot encoded labels to class indices\n",
    "        if len(labels.shape) > 1 and labels.shape[-1] > 1:  # Likely one-hot\n",
    "            labels_tf = tf.argmax(labels, axis=1, output_type=tf.int32)\n",
    "        else:\n",
    "            labels_tf = tf.convert_to_tensor(labels, dtype=tf.int32)\n",
    "\n",
    "        # Debugging: Print shapes\n",
    "        print(f\"Features shape: {features_tf.shape}, Labels shape: {labels_tf.shape}\")\n",
    "\n",
    "        # Get predictions\n",
    "        predictions = model(features_tf, training=False)\n",
    "        predicted = tf.argmax(predictions, axis=1, output_type=tf.int32)\n",
    "\n",
    "        # Accumulate predictions and labels\n",
    "        all_preds.extend(predicted.numpy())\n",
    "        all_labels.extend(labels_tf.numpy())\n",
    "\n",
    "\n",
    "        # Compute loss\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels_tf, logits=predictions)\n",
    "        total_loss += tf.reduce_mean(loss).numpy()\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # Classification report\n",
    "    class_names = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"] \n",
    "    classification_report_str = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "\n",
    "    # Append metrics to a file\n",
    "    with open(output_file, \"w\") as file:\n",
    "        file.write(f\"Evaluation Metrics for Client {client_idx + 1}:\\n\")\n",
    "        file.write(f\"Accuracy: {accuracy * 100:.2f}%\\n\")\n",
    "        file.write(f\"Loss: {total_loss / len(test_loader):.4f}\\n\")\n",
    "        file.write(f\"Precision: {precision:.4f}\\n\")\n",
    "        file.write(f\"Recall: {recall:.4f}\\n\")\n",
    "        file.write(f\"F1 Score: {f1:.4f}\\n\\n\")\n",
    "        file.write(\"Classification Report:\\n\")\n",
    "        file.write(classification_report_str)\n",
    "        file.write(\"\\nConfusion Matrix:\\n\")\n",
    "        file.write(\"\\n\".join([\"\\t\".join(map(str, row)) for row in conf_matrix]))\n",
    "        file.write(\"\\n\" + \"-\" * 50 + \"\\n\")\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"\\nClassification Report:\\n\", classification_report_str)\n",
    "    print(f\"\\nAccuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Loss: {total_loss / len(test_loader):.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Plot and save heatmap\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title(f'Confusion Matrix (Client {client_idx + 1})')\n",
    "    plt.savefig(os.path.join(output_dir, f\"confusion_matrix_Client_{client_idx + 1}.png\"))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd1c44c",
   "metadata": {},
   "source": [
    "### Replace path with the respective NON-IID dataset paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3215e56-6f72-401c-a2e6-fc8235507557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories for each client\n",
    "\n",
    "split_dirs = [\n",
    "    \"../NON_IID/Model_1\",\n",
    "    \"../NON_IID/Model_2\",\n",
    "    \"../NON_IID/Model_3\",\n",
    "    \"../NON_IID/Model_4\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05a0a17",
   "metadata": {},
   "source": [
    "### Load the NON-IID dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "554cb072-483e-4efb-a73e-96f9efdd0ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 image sizes: torch.Size([25, 224, 224, 3])\n"
     ]
    }
   ],
   "source": [
    "# Updated image transformations: Normalize first, then permute\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),          # Convert image to tensor format (C, H, W)\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize\n",
    "    transforms.Lambda(lambda x: x.permute(1, 2, 0))  # Permute to (H, W, C)\n",
    "])\n",
    "\n",
    "def get_tumor_dataloaders(split_dirs, batch_size=25, shuffle=True):\n",
    "    \"\"\"\n",
    "    Returns data loaders for all clients for both training and testing sets.\n",
    "    \"\"\"\n",
    "    tumor_iid_train_dls = []\n",
    "    tumor_iid_test_dls = []\n",
    "\n",
    "    for client_idx, client_dir in enumerate(split_dirs):\n",
    "        # Get the directory for the current client\n",
    "        train_dir = os.path.join(client_dir, 'train')\n",
    "        test_dir = os.path.join(client_dir, 'test')\n",
    "\n",
    "        # Check if the directories exist\n",
    "        if not os.path.exists(train_dir) or not os.path.exists(test_dir):\n",
    "            print(f\"Directory not found for client {client_idx + 1}:\")\n",
    "            print(f\"Train dir: {train_dir}\")\n",
    "            print(f\"Test dir: {test_dir}\")\n",
    "            continue\n",
    "\n",
    "        # Load training data for the current client\n",
    "        train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "        # Load testing data for the current client\n",
    "        test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Append the dataloaders for the current client to the list\n",
    "        tumor_iid_train_dls.append(train_loader)\n",
    "        tumor_iid_test_dls.append(test_loader)\n",
    "\n",
    "    return tumor_iid_train_dls, tumor_iid_test_dls\n",
    "\n",
    "# Get the training and testing data loaders\n",
    "Tumor_iid_train_dls, Tumor_iid_test_dls = get_tumor_dataloaders(split_dirs, batch_size=25)\n",
    "\n",
    "# Checking the sizes of the images in the data loaders to verify the shape\n",
    "for batch_idx, (images, labels) in enumerate(Tumor_iid_train_dls[0]):  # Checking for client 1\n",
    "    print(f\"Batch {batch_idx} image sizes: {images.size()}\")  # Should print torch.Size([25, 224, 224, 3])\n",
    "    break  # Check only the first batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c63034e",
   "metadata": {},
   "source": [
    "### Converts a PyTorch DataLoader to a TensorFlow dataset with one-hot encoded labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e653b82-6b74-4ec2-b594-97c814448325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def pytorch_to_tf_dataset(pytorch_loader, num_classes):\n",
    "    images, labels = [], []\n",
    "    for batch_images, batch_labels in pytorch_loader:\n",
    "        # Convert PyTorch tensors to NumPy arrays and permute to (Batch, Height, Width, Channels)\n",
    "        images.append(batch_images.permute(0, 2, 1, 3).numpy())\n",
    "        # One-hot encode labels\n",
    "        labels.append(to_categorical(batch_labels.numpy(), num_classes=num_classes))\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    images = np.concatenate(images, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    \n",
    "    # Create TensorFlow dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    return dataset.batch(pytorch_loader.batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7b0ffc",
   "metadata": {},
   "source": [
    "### Main method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c583c345-44b4-4260-906b-2b7a829a707a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and testing on dataset: Model_1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 14:09:09.364072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31132 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 8s 0us/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 14:09:26.380498: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [1321,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-12-04 14:09:42.217797: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n",
      "2024-12-04 14:09:43.555674: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f2d2c4cacf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-04 14:09:43.555727: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-12-04 14:09:43.561386: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-04 14:09:43.707599: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - ETA: 0s - loss: 0.5334 - accuracy: 0.7827"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 14:10:28.257943: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [342,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 65s 411ms/step - loss: 0.5334 - accuracy: 0.7827 - val_loss: 1.8352 - val_accuracy: 0.6140\n",
      "Epoch 2/10\n",
      "53/53 [==============================] - 16s 309ms/step - loss: 0.2450 - accuracy: 0.9008 - val_loss: 1.2699 - val_accuracy: 0.6140\n",
      "Epoch 3/10\n",
      "53/53 [==============================] - 16s 305ms/step - loss: 0.1697 - accuracy: 0.9478 - val_loss: 1.2917 - val_accuracy: 0.4737\n",
      "Epoch 4/10\n",
      "53/53 [==============================] - 16s 305ms/step - loss: 0.0641 - accuracy: 0.9780 - val_loss: 1.3393 - val_accuracy: 0.6199\n",
      "Epoch 5/10\n",
      "53/53 [==============================] - 16s 309ms/step - loss: 0.0399 - accuracy: 0.9886 - val_loss: 1.2661 - val_accuracy: 0.4415\n",
      "Epoch 6/10\n",
      "53/53 [==============================] - 16s 309ms/step - loss: 0.0484 - accuracy: 0.9886 - val_loss: 1.2099 - val_accuracy: 0.5351\n",
      "Epoch 7/10\n",
      "53/53 [==============================] - 16s 305ms/step - loss: 0.0364 - accuracy: 0.9886 - val_loss: 1.4425 - val_accuracy: 0.4181\n",
      "Epoch 8/10\n",
      "53/53 [==============================] - 16s 308ms/step - loss: 0.0160 - accuracy: 0.9970 - val_loss: 0.9953 - val_accuracy: 0.7573\n",
      "Epoch 9/10\n",
      "53/53 [==============================] - 16s 306ms/step - loss: 0.0182 - accuracy: 0.9939 - val_loss: 1.6070 - val_accuracy: 0.6404\n",
      "Epoch 10/10\n",
      "53/53 [==============================] - 16s 309ms/step - loss: 0.0616 - accuracy: 0.9818 - val_loss: 0.6617 - val_accuracy: 0.8509\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (17, 224, 224, 3), Labels shape: (17,)\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.86      0.97      0.91       210\n",
      "  meningioma       0.50      0.03      0.06        32\n",
      "     notumor       0.78      0.94      0.85        50\n",
      "   pituitary       0.91      0.78      0.84        50\n",
      "\n",
      "    accuracy                           0.85       342\n",
      "   macro avg       0.76      0.68      0.67       342\n",
      "weighted avg       0.82      0.85      0.81       342\n",
      "\n",
      "\n",
      "Accuracy: 85.09%\n",
      "Loss: 0.8917\n",
      "Precision: 0.8224\n",
      "Recall: 0.8509\n",
      "F1 Score: 0.8135\n",
      "Training and evaluation completed for Model_1\n",
      "\n",
      "\n",
      "Training and testing on dataset: Model_2\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 14:13:16.917163: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [1339,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - ETA: 0s - loss: 0.5400 - accuracy: 0.7879"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 14:14:17.697336: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [340,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 64s 394ms/step - loss: 0.5400 - accuracy: 0.7879 - val_loss: 1.5048 - val_accuracy: 0.6176\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 16s 303ms/step - loss: 0.1860 - accuracy: 0.9470 - val_loss: 3.2836 - val_accuracy: 0.6176\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 16s 304ms/step - loss: 0.0922 - accuracy: 0.9701 - val_loss: 1.6994 - val_accuracy: 0.6176\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 17s 307ms/step - loss: 0.0781 - accuracy: 0.9798 - val_loss: 1.3525 - val_accuracy: 0.5765\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 16s 304ms/step - loss: 0.0373 - accuracy: 0.9910 - val_loss: 1.3667 - val_accuracy: 0.6118\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 16s 306ms/step - loss: 0.0286 - accuracy: 0.9910 - val_loss: 0.9517 - val_accuracy: 0.6441\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 16s 304ms/step - loss: 0.0506 - accuracy: 0.9851 - val_loss: 2.2389 - val_accuracy: 0.6118\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 16s 305ms/step - loss: 0.0416 - accuracy: 0.9873 - val_loss: 2.1042 - val_accuracy: 0.6412\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 16s 304ms/step - loss: 0.0228 - accuracy: 0.9933 - val_loss: 1.1593 - val_accuracy: 0.6647\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 16s 306ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.6716 - val_accuracy: 0.8000\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (15, 224, 224, 3), Labels shape: (15,)\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.66      0.63      0.64        30\n",
      "  meningioma       0.81      0.98      0.88       210\n",
      "     notumor       1.00      0.52      0.68        50\n",
      "   pituitary       0.71      0.44      0.54        50\n",
      "\n",
      "    accuracy                           0.80       340\n",
      "   macro avg       0.79      0.64      0.69       340\n",
      "weighted avg       0.81      0.80      0.78       340\n",
      "\n",
      "\n",
      "Accuracy: 80.00%\n",
      "Loss: 0.9584\n",
      "Precision: 0.8077\n",
      "Recall: 0.8000\n",
      "F1 Score: 0.7831\n",
      "Training and evaluation completed for Model_2\n",
      "\n",
      "\n",
      "Training and testing on dataset: Model_3\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 14:17:08.047830: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [1595,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - ETA: 0s - loss: 0.4170 - accuracy: 0.7994"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 14:18:10.449123: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [367,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 65s 372ms/step - loss: 0.4170 - accuracy: 0.7994 - val_loss: 1.4801 - val_accuracy: 0.6948\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 20s 305ms/step - loss: 0.2629 - accuracy: 0.8734 - val_loss: 0.9699 - val_accuracy: 0.6948\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 19s 302ms/step - loss: 0.1567 - accuracy: 0.9373 - val_loss: 4.3494 - val_accuracy: 0.1962\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 19s 304ms/step - loss: 0.1112 - accuracy: 0.9649 - val_loss: 5.0580 - val_accuracy: 0.5749\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 19s 303ms/step - loss: 0.0843 - accuracy: 0.9705 - val_loss: 2.2108 - val_accuracy: 0.3406\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 20s 306ms/step - loss: 0.0575 - accuracy: 0.9843 - val_loss: 0.8835 - val_accuracy: 0.7384\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 19s 302ms/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 1.0949 - val_accuracy: 0.7221\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 19s 303ms/step - loss: 0.0193 - accuracy: 0.9944 - val_loss: 1.0194 - val_accuracy: 0.7956\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 19s 304ms/step - loss: 0.0207 - accuracy: 0.9962 - val_loss: 1.0272 - val_accuracy: 0.7657\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 19s 302ms/step - loss: 0.0349 - accuracy: 0.9906 - val_loss: 2.0302 - val_accuracy: 0.7084\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (17, 224, 224, 3), Labels shape: (17,)\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.23      0.97      0.37        30\n",
      "  meningioma       0.74      0.44      0.55        32\n",
      "     notumor       0.98      0.83      0.90       255\n",
      "   pituitary       1.00      0.10      0.18        50\n",
      "\n",
      "    accuracy                           0.71       367\n",
      "   macro avg       0.74      0.58      0.50       367\n",
      "weighted avg       0.90      0.71      0.73       367\n",
      "\n",
      "\n",
      "Accuracy: 70.84%\n",
      "Loss: 1.0370\n",
      "Precision: 0.9011\n",
      "Recall: 0.7084\n",
      "F1 Score: 0.7283\n",
      "Training and evaluation completed for Model_3\n",
      "\n",
      "\n",
      "Training and testing on dataset: Model_4\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 14:21:30.079611: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [1457,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - ETA: 0s - loss: 0.4439 - accuracy: 0.7859"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 14:22:27.808285: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [262,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 61s 369ms/step - loss: 0.4439 - accuracy: 0.7859 - val_loss: 1.3632 - val_accuracy: 0.5725\n",
      "Epoch 2/10\n",
      "59/59 [==============================] - 18s 297ms/step - loss: 0.2938 - accuracy: 0.8874 - val_loss: 1.4932 - val_accuracy: 0.1908\n",
      "Epoch 3/10\n",
      "59/59 [==============================] - 17s 297ms/step - loss: 0.1508 - accuracy: 0.9513 - val_loss: 4.7427 - val_accuracy: 0.1908\n",
      "Epoch 4/10\n",
      "59/59 [==============================] - 17s 296ms/step - loss: 0.0746 - accuracy: 0.9774 - val_loss: 3.8643 - val_accuracy: 0.1603\n",
      "Epoch 5/10\n",
      "59/59 [==============================] - 17s 297ms/step - loss: 0.0915 - accuracy: 0.9739 - val_loss: 3.9358 - val_accuracy: 0.1908\n",
      "Epoch 6/10\n",
      "59/59 [==============================] - 18s 301ms/step - loss: 0.0379 - accuracy: 0.9904 - val_loss: 4.6617 - val_accuracy: 0.2481\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (12, 224, 224, 3), Labels shape: (12,)\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.00      0.00      0.00        30\n",
      "  meningioma       0.00      0.00      0.00        32\n",
      "     notumor       0.00      0.00      0.00        50\n",
      "   pituitary       0.57      1.00      0.73       150\n",
      "\n",
      "    accuracy                           0.57       262\n",
      "   macro avg       0.14      0.25      0.18       262\n",
      "weighted avg       0.33      0.57      0.42       262\n",
      "\n",
      "\n",
      "Accuracy: 57.25%\n",
      "Loss: 1.3799\n",
      "Precision: 0.3278\n",
      "Recall: 0.5725\n",
      "F1 Score: 0.4169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/ml_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/envs/ml_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/envs/ml_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/envs/ml_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluation completed for Model_4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Iterate over all clients' datasets, here 4 clients, 4 datasets\n",
    "    for client_idx in range(len(split_dirs)):\n",
    "        print(f\"\\nTraining and testing on dataset: Model_{client_idx + 1}\\n\")\n",
    "        \n",
    "        # Load data for the current client\n",
    "        train_loader = Tumor_iid_train_dls[client_idx]\n",
    "        test_loader = Tumor_iid_test_dls[client_idx]\n",
    "\n",
    "        # Number of classes in your dataset\n",
    "        num_classes = 4\n",
    "\n",
    "        # Convert PyTorch DataLoaders to TensorFlow datasets\n",
    "        tf_train_dataset = pytorch_to_tf_dataset(train_loader, num_classes)\n",
    "        tf_test_dataset = pytorch_to_tf_dataset(test_loader, num_classes)\n",
    "\n",
    "        # Build Model\n",
    "        model = ResNet50_CBAM_Model()\n",
    "\n",
    "        # Use these datasets for training\n",
    "        history = compile_and_train(model, tf_train_dataset, tf_test_dataset, epochs=10, learning_rate=0.0001)\n",
    "\n",
    "        # Evaluate and Save Results\n",
    "        evaluate_global_model(model, tf_test_dataset, client_idx, output_dir=\"Reset50_model_results\")\n",
    "\n",
    "        print(f\"Training and evaluation completed for Model_{client_idx + 1}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
