{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f71c206-ab25-4aff-92ee-3bbde084bc8a",
   "metadata": {},
   "source": [
    "# Import Libraries & methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfb137ff-0915-42a0-93db-933b287750e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 08:09:50.903243: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-11 08:09:51.826304: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Flatten, Input, BatchNormalization, Dense, Activation, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39974288-942d-48f4-af88-592ec2b24a21",
   "metadata": {},
   "source": [
    "# FedProx Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "146a4e25-c86e-476c-a8c1-933df291a0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_classifier(predictions, labels):\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=predictions)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "def loss_dataset(model, dataset, loss_f):\n",
    "    loss = 0\n",
    "    for idx, (features, labels) in enumerate(dataset):\n",
    "        # Convert PyTorch tensors to NumPy and then to TensorFlow tensors\n",
    "        features_np = features.detach().cpu().numpy()\n",
    "        labels_np = labels.detach().cpu().numpy()\n",
    "\n",
    "        features_tf = tf.convert_to_tensor(features_np, dtype=tf.float32)\n",
    "        labels_tf = tf.convert_to_tensor(labels_np, dtype=tf.int32)\n",
    "\n",
    "        predictions = model(features_tf)\n",
    "        loss += loss_f(predictions, labels_tf)\n",
    "    loss /= (idx + 1)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def accuracy_dataset(model, dataset):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for features, labels in dataset:\n",
    "        # Convert PyTorch tensors to NumPy and then to TensorFlow tensors\n",
    "        features_np = features.detach().cpu().numpy()\n",
    "        labels_np = labels.detach().cpu().numpy()\n",
    "\n",
    "        features_tf = tf.convert_to_tensor(features_np, dtype=tf.float32)\n",
    "        labels_tf = tf.convert_to_tensor(labels_np, dtype=tf.int32)\n",
    "\n",
    "        predictions = model(features_tf)\n",
    "        predicted = tf.argmax(predictions, axis=1, output_type=tf.int32)\n",
    "        correct += tf.reduce_sum(tf.cast(tf.equal(predicted, labels_tf), tf.int32)).numpy()\n",
    "        total += labels_tf.shape[0]\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def train_step(model, model_0, mu, optimizer, train_data, loss_f):\n",
    "    total_loss = 0\n",
    "    for idx, (features, labels) in enumerate(train_data):\n",
    "        # Convert PyTorch tensors to NumPy and then to TensorFlow tensors\n",
    "        features_np = features.detach().cpu().numpy()\n",
    "        labels_np = labels.detach().cpu().numpy()\n",
    "\n",
    "        features_tf = tf.convert_to_tensor(features_np, dtype=tf.float32)\n",
    "        labels_tf = tf.convert_to_tensor(labels_np, dtype=tf.int32)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(features_tf)\n",
    "            loss = loss_f(predictions, labels_tf)\n",
    "            loss += mu / 2 * difference_models_norm_2(model, model_0)\n",
    "\n",
    "        total_loss += loss\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return total_loss / (idx + 1)\n",
    "\n",
    "\n",
    "def local_learning(model, mu, optimizer, train_data, epochs, loss_f):\n",
    "    # Clone the model instead of using deepcopy\n",
    "    model_0 = tf.keras.models.clone_model(model)\n",
    "    model_0.set_weights(model.get_weights())  # Set weights to be identical initially\n",
    "\n",
    "    for e in range(epochs):\n",
    "        local_loss = train_step(model, model_0, mu, optimizer, train_data, loss_f)\n",
    "\n",
    "    return local_loss\n",
    "\n",
    "\n",
    "def difference_models_norm_2(model_1, model_2):\n",
    "    norm = tf.reduce_sum([tf.reduce_sum(tf.square(w1 - w2)) for w1, w2 in zip(model_1.trainable_variables, model_2.trainable_variables)])\n",
    "    return norm\n",
    "\n",
    "def set_to_zero_model_weights(model):\n",
    "    for layer_weights in model.trainable_variables:\n",
    "        layer_weights.assign(tf.zeros_like(layer_weights))\n",
    "\n",
    "def average_models(model, clients_models_hist, weights):\n",
    "    set_to_zero_model_weights(model)\n",
    "    for k, client_hist in enumerate(clients_models_hist):\n",
    "        for idx, layer_weights in enumerate(model.trainable_variables):\n",
    "            contribution = client_hist[idx] * weights[k]\n",
    "            layer_weights.assign_add(contribution)\n",
    "\n",
    "#_______________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70c4bf4c-4d12-4942-98b0-6a4c65695cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FedProx(model, training_sets, n_iter, testing_sets, mu=0.1, epochs=1, lr=0.0001, decay=1):\n",
    "    # Verify that `model` is a Keras model instance\n",
    "    if not isinstance(model, tf.keras.Model):\n",
    "        raise TypeError(\"The provided model is not a TensorFlow Keras model. Please provide a valid Keras model.\")\n",
    "\n",
    "    loss_f = loss_classifier\n",
    "    K = len(training_sets)\n",
    "    n_samples = sum([len(db) for db in training_sets])\n",
    "    weights = [len(db) / n_samples for db in training_sets]\n",
    "    print(\"Clients' weights:\", weights)\n",
    "\n",
    "    # Initialize history lists for training and testing\n",
    "    train_loss_hist = []\n",
    "    train_acc_hist = []\n",
    "    test_loss_hist = []\n",
    "    test_acc_hist = []\n",
    "    models_hist = []\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        clients_params = []\n",
    "        clients_losses = []\n",
    "        clients_accuracies = []\n",
    "\n",
    "        for k in range(K):\n",
    "            # Clone the model and set weights for local training\n",
    "            local_model = tf.keras.models.clone_model(model)\n",
    "            local_model.set_weights(model.get_weights())\n",
    "\n",
    "            local_optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "\n",
    "            # Perform local training and track the loss\n",
    "            local_loss = local_learning(local_model, mu, local_optimizer, training_sets[k], epochs, loss_f)\n",
    "            clients_losses.append(local_loss)\n",
    "\n",
    "            # Track training accuracy for the client\n",
    "            train_acc = accuracy_dataset(local_model, training_sets[k])\n",
    "            clients_accuracies.append(train_acc)\n",
    "\n",
    "            # Store model parameters (deep copy to ensure immutability)\n",
    "            clients_params.append([tf.identity(tens_param) for tens_param in local_model.trainable_variables])\n",
    "\n",
    "        # Average the local models into the global model\n",
    "        average_models(model, clients_params, weights=weights)\n",
    "        models_hist.append(deepcopy(clients_params))\n",
    "\n",
    "        # Collect metrics for this iteration\n",
    "        train_loss_hist.append(clients_losses)\n",
    "        train_acc_hist.append(clients_accuracies)\n",
    "\n",
    "        # Compute testing metrics using the global model\n",
    "        test_loss_hist.append([loss_dataset(model, dl, loss_f).numpy() for dl in testing_sets])\n",
    "        test_acc_hist.append([accuracy_dataset(model, dl) for dl in testing_sets])\n",
    "\n",
    "        # Update learning rate by decay factor\n",
    "        lr *= decay\n",
    "        print(f'====> i: {i+1} Server Test Accuracy: {test_acc_hist[-1]}')\n",
    "\n",
    "    return model, train_loss_hist, train_acc_hist, test_loss_hist, test_acc_hist\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dfbd41-5dc5-432d-80a7-2d1adb20ace1",
   "metadata": {},
   "source": [
    "# To save model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4371450-b7db-442a-869d-2725b3553a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the history to a file with detailed formatting\n",
    "def save_history_to_file(filename, train_loss, train_acc, test_loss, test_acc):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"FedProx Training and Testing Metrics\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\")\n",
    "        \n",
    "        for i in range(len(train_loss)):\n",
    "            try:\n",
    "                # Ensure data is printed in the format shown, converting Tensors to their numpy values if needed\n",
    "                train_loss_str = [float(tensor.numpy()) if hasattr(tensor, 'numpy') else float(tensor) for tensor in train_loss[i]]\n",
    "                train_acc_str = [float(val) for val in train_acc[i]]\n",
    "                test_loss_str = [float(val) for val in test_loss[i]]\n",
    "                test_acc_str = [float(val) for val in test_acc[i]]\n",
    "                \n",
    "                f.write(f\"Iteration {i + 31}:\\n\")\n",
    "                f.write(f\"Train Loss: {train_loss_str}\\n\")\n",
    "                f.write(f\"Train Accuracy: {train_acc_str}\\n\")\n",
    "                f.write(f\"Test Loss: {test_loss_str}\\n\")\n",
    "                f.write(f\"Test Accuracy: {test_acc_str}\\n\")\n",
    "                f.write(\"-\" * 50 + \"\\n\")\n",
    "                \n",
    "            except (ValueError, TypeError) as e:\n",
    "                f.write(f\"Error processing round {i + 31}: {e}\\n\")\n",
    "                f.write(\"-\" * 50 + \"\\n\")\n",
    "    \n",
    "    print(f\"History saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f485cd-e3f3-45fa-81b9-222579b3ff23",
   "metadata": {},
   "source": [
    "# Load training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9eec383d-9d6a-45ae-9c9a-a8de4001ab20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 image sizes: torch.Size([25, 224, 224, 3])\n"
     ]
    }
   ],
   "source": [
    "# Directories for each client\n",
    "split_dirs = [\n",
    "    \"Federated_Learning_NON_IID/Model_1\",\n",
    "    \"Federated_Learning_NON_IID/Model_2\",\n",
    "    \"Federated_Learning_NON_IID/Model_3\",\n",
    "    \"Federated_Learning_NON_IID/Model_4\"\n",
    "]\n",
    "\n",
    "# Number of clients\n",
    "n_clients = len(split_dirs)\n",
    "\n",
    "# Updated image transformations: Normalize first, then permute\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),          # Convert image to tensor format (C, H, W)\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize\n",
    "    transforms.Lambda(lambda x: x.permute(1, 2, 0))  # Permute to (H, W, C)\n",
    "])\n",
    "\n",
    "def get_tumor_dataloaders(split_dirs, batch_size=25, shuffle=True):\n",
    "    \"\"\"\n",
    "    Returns data loaders for all clients for both training and testing sets.\n",
    "    \"\"\"\n",
    "    tumor_iid_train_dls = []\n",
    "    tumor_iid_test_dls = []\n",
    "\n",
    "    for client_idx, client_dir in enumerate(split_dirs):\n",
    "        # Get the directory for the current client\n",
    "        train_dir = os.path.join(client_dir, 'train')\n",
    "        test_dir = os.path.join(client_dir, 'test')\n",
    "\n",
    "        # Check if the directories exist\n",
    "        if not os.path.exists(train_dir) or not os.path.exists(test_dir):\n",
    "            print(f\"Directory not found for client {client_idx + 1}:\")\n",
    "            print(f\"Train dir: {train_dir}\")\n",
    "            print(f\"Test dir: {test_dir}\")\n",
    "            continue\n",
    "\n",
    "        # Load training data for the current client\n",
    "        train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "        # Load testing data for the current client\n",
    "        test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Append the dataloaders for the current client to the list\n",
    "        tumor_iid_train_dls.append(train_loader)\n",
    "        tumor_iid_test_dls.append(test_loader)\n",
    "\n",
    "    return tumor_iid_train_dls, tumor_iid_test_dls\n",
    "\n",
    "# Get the training and testing data loaders\n",
    "Tumor_iid_train_dls, Tumor_iid_test_dls = get_tumor_dataloaders(split_dirs, batch_size=25)\n",
    "\n",
    "# Checking the sizes of the images in the data loaders to verify the shape\n",
    "for batch_idx, (images, labels) in enumerate(Tumor_iid_train_dls[0]):  # Checking for client 1\n",
    "    print(f\"Batch {batch_idx} image sizes: {images.size()}\")  # Should print torch.Size([25, 224, 224, 3])\n",
    "    break  # Check only the first batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f658c8fb-cc6b-466e-9163-1b0bf7b43c9b",
   "metadata": {},
   "source": [
    "# ResNet50 + CBAM model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee94b47f-44c3-45ef-b060-e88e6290cc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- CBAM Block Definition ------------------\n",
    "def cbam_block(inputs, reduction_ratio=0.5):\n",
    "    channels = inputs.shape[-1]\n",
    "\n",
    "    # Channel attention\n",
    "    avg_pool = layers.GlobalAveragePooling2D()(inputs)\n",
    "    max_pool = layers.GlobalMaxPooling2D()(inputs)\n",
    "    shared_layer_1 = layers.Dense(int(channels * reduction_ratio), activation='relu', use_bias=True)\n",
    "    shared_layer_2 = layers.Dense(channels, activation='relu', use_bias=True)\n",
    "\n",
    "    avg_pool = shared_layer_1(avg_pool)\n",
    "    avg_pool = shared_layer_2(avg_pool)\n",
    "    max_pool = shared_layer_1(max_pool)\n",
    "    max_pool = shared_layer_2(max_pool)\n",
    "\n",
    "    attention = layers.Add()([avg_pool, max_pool])\n",
    "    attention = layers.Activation('sigmoid')(attention)\n",
    "    attention = layers.Reshape((1, 1, channels))(attention)\n",
    "    scaled_inputs = layers.Multiply()([inputs, attention])\n",
    "\n",
    "    # Spatial attention\n",
    "    squeeze = layers.Conv2D(filters=1, kernel_size=1, activation='sigmoid', use_bias=False)(scaled_inputs)\n",
    "    expanded_inputs = layers.Multiply()([scaled_inputs, squeeze])\n",
    "\n",
    "    return expanded_inputs\n",
    "\n",
    "# ---------------- Model Definitions ------------------\n",
    "\n",
    "# ResNet50 with CBAM and a more complex output structure\n",
    "def ResNet50_CBAM_Model():\n",
    "    input_shape = (224, 224, 3)\n",
    "    resnet50 = tf.keras.applications.ResNet50(include_top=False, input_shape=input_shape, weights='imagenet')\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(resnet50.output)\n",
    "    x = layers.Dense(units=1024, activation='relu')(x)\n",
    "    x = layers.Dense(units=512, activation='relu')(x)\n",
    "    x = layers.Dense(units=256, activation='relu')(x)\n",
    "    x = layers.Dense(units=128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.Reshape((1, 1, 128))(x)\n",
    "    x_max = layers.GlobalMaxPooling2D()(x)\n",
    "    x_avg = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Concatenate()([x_max, x_avg])\n",
    "    x = layers.Dense(units=4, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs=resnet50.input, outputs=x, name='ResNet50_CBAM_Model')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7380c4c8-86bf-4300-8147-98a3ee95ed7b",
   "metadata": {},
   "source": [
    "# Model Intialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65edeb04-b1ba-4d37-b53f-71fd508a86b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 11:51:48.030963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31132 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 8s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50_CBAM_Model()\n",
    "\n",
    "# Compile models\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a4a26-e380-443e-9b70-a236426e1747",
   "metadata": {},
   "source": [
    "# Load original testing dataset (without augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7255b70-43fc-41be-9f1c-ac46cf016964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),          # Convert image to tensor format (C, H, W)\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize\n",
    "    transforms.Lambda(lambda x: x.permute(1, 2, 0))  # Permute to (H, W, C)\n",
    "])\n",
    "\n",
    "# Load the testing dataset\n",
    "test_dir = 'BrainTumor_MRI/Testing'\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Class names mapping (adjust if necessary)\n",
    "class_names = test_dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77d67c7-7b56-4639-9a45-136b43ed70a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# To evaluate the trained model\n",
    "# Save the confusion matrix + performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1da4a128-b9ec-408f-a166-e0a1bc6c0746",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define class names\n",
    "class_names = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]  # Modify according to your classes\n",
    "MODEL_PATH = 'model_results_mu=0.1/'\n",
    "\n",
    "# Function to evaluate the global model on the testing dataset\n",
    "def evaluate_global_model(model, test_loader, output_file=f'{MODEL_PATH}Global_Model_Results_mu=0.1.txt'):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0\n",
    "\n",
    "    for features, labels in test_loader:\n",
    "        # Convert to TensorFlow tensors\n",
    "        features_np = features.detach().cpu().numpy()\n",
    "        labels_np = labels.detach().cpu().numpy()\n",
    "\n",
    "        features_tf = tf.convert_to_tensor(features_np, dtype=tf.float32)\n",
    "        labels_tf = tf.convert_to_tensor(labels_np, dtype=tf.int32)\n",
    "\n",
    "        # Get predictions\n",
    "        predictions = model(features_tf)\n",
    "        predicted = tf.argmax(predictions, axis=1, output_type=tf.int32)\n",
    "\n",
    "        # Accumulate predictions and labels\n",
    "        all_preds.extend(predicted.numpy())\n",
    "        all_labels.extend(labels_np)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels_tf, logits=predictions)\n",
    "        total_loss += tf.reduce_mean(loss).numpy()\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # Classification report\n",
    "    classification_report_str = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "\n",
    "    # Append metrics to a file\n",
    "    with open(output_file, \"a\") as file:\n",
    "        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')  # Get current timestamp\n",
    "        file.write(f\"Evaluation Timestamp: {timestamp}\\n\")\n",
    "        file.write(\"Evaluation Metrics:\\n\")\n",
    "        file.write(f\"Accuracy: {accuracy * 100:.2f}%\\n\")\n",
    "        file.write(f\"Loss: {total_loss / len(test_loader):.4f}\\n\")\n",
    "        file.write(f\"Precision: {precision:.4f}\\n\")\n",
    "        file.write(f\"Recall: {recall:.4f}\\n\")\n",
    "        file.write(f\"F1 Score: {f1:.4f}\\n\\n\")\n",
    "        file.write(\"Classification Report:\\n\")\n",
    "        file.write(classification_report_str)\n",
    "        file.write(\"\\nConfusion Matrix:\\n\")\n",
    "        file.write(\"\\n\".join([\"\\t\".join(map(str, row)) for row in conf_matrix]))\n",
    "        file.write(\"\\n\" + \"-\" * 50 + \"\\n\")\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"\\nClassification Report:\\n\", classification_report_str)\n",
    "    print(f\"\\nAccuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Loss: {total_loss / len(test_loader):.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Plot and save heatmap\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    heatmap_path = f'model_results_mu=0.1/confusion_matrix_{timestamp.replace(\" \", \"_\").replace(\":\", \"-\")}.png'\n",
    "    plt.savefig(heatmap_path)  # Save as PNG with timestamp\n",
    "    plt.close()  # Close the figure\n",
    "    \n",
    "    current_loss = (total_loss / len(test_loader))\n",
    "    return current_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f596786-1c87-406c-9ba2-cbc7a2cefbd5",
   "metadata": {},
   "source": [
    "# FedProx hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8558fd6a-9a45-4198-9496-7a5d27b69bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial parameters\n",
    "n_iter = 100\n",
    "rounds_per_segment = 10\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf794472-b888-4ab1-bc5a-81ada0e6a7fb",
   "metadata": {},
   "source": [
    "mu & learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "508a715d-bd60-4283-935f-b3474cda4aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "mu = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87d1e2a0-6b8d-4de4-bb1b-81581aac34f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store cumulative training and testing metrics\n",
    "all_train_loss = []\n",
    "all_train_acc = []\n",
    "all_test_loss = []\n",
    "all_test_acc = []\n",
    "# Load the initial model\n",
    "# Trained_MODEL_PATH = ''\n",
    "# model = tf.keras.models.load_model(Trained_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d2a449-a99e-4410-ae90-b76ae7c5f994",
   "metadata": {},
   "source": [
    "# 100 rounds training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7f718d2-79df-40c9-aee7-a3768ef08793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize early stopping parameters\n",
    "patience = 20\n",
    "best_metric = 0.9049 #0.9582 #None  # Track the lowest validation loss\n",
    "no_improve_rounds = 10  # Counter for rounds without improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b458031e-432d-415d-881f-a7d237c1f741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting rounds 1 to 10\n",
      "Clients' weights: [0.22620689655172413, 0.2303448275862069, 0.2868965517241379, 0.25655172413793104]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 11:53:25.193992: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n",
      "2024-12-08 11:53:28.360953: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x236f2680 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-08 11:53:28.360990: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-12-08 11:53:28.439821: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f58903ca160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f58903ca160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "====> i: 1 Server Test Accuracy: [26.904761904761905, 25.476190476190474, 27.058823529411764, 30.333333333333332]\n",
      "====> i: 2 Server Test Accuracy: [40.476190476190474, 32.61904761904762, 45.3921568627451, 47.833333333333336]\n",
      "====> i: 3 Server Test Accuracy: [54.404761904761905, 50.833333333333336, 57.84313725490196, 62.833333333333336]\n",
      "====> i: 4 Server Test Accuracy: [53.333333333333336, 40.357142857142854, 44.411764705882355, 53.0]\n",
      "====> i: 5 Server Test Accuracy: [49.88095238095238, 52.857142857142854, 53.431372549019606, 52.166666666666664]\n",
      "====> i: 6 Server Test Accuracy: [51.54761904761905, 47.61904761904762, 47.549019607843135, 54.0]\n",
      "====> i: 7 Server Test Accuracy: [52.73809523809524, 56.42857142857143, 52.05882352941177, 59.0]\n",
      "====> i: 8 Server Test Accuracy: [52.38095238095238, 46.666666666666664, 43.23529411764706, 52.833333333333336]\n",
      "====> i: 9 Server Test Accuracy: [52.73809523809524, 53.333333333333336, 52.450980392156865, 52.833333333333336]\n",
      "====> i: 10 Server Test Accuracy: [53.92857142857143, 57.857142857142854, 54.31372549019608, 64.33333333333333]\n",
      "Evaluating global model for rounds 1 to 10\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.69      0.73      0.71       300\n",
      "  meningioma       0.54      0.50      0.52       306\n",
      "     notumor       0.79      0.79      0.79       405\n",
      "   pituitary       0.70      0.73      0.72       300\n",
      "\n",
      "    accuracy                           0.69      1311\n",
      "   macro avg       0.68      0.69      0.68      1311\n",
      "weighted avg       0.69      0.69      0.69      1311\n",
      "\n",
      "\n",
      "Accuracy: 69.41%\n",
      "Loss: 1.0394\n",
      "Precision: 0.6913\n",
      "Recall: 0.6941\n",
      "F1 Score: 0.6922\n",
      "Current validation loss: 1.0394\n",
      "Best model updated and saved at: model_results_mu=0.1/best_model_mu=0.1.h5\n",
      "Model saved at: model_results_mu=0.1/global_model_rounds_10_mu=0.1.h5\n",
      "Starting rounds 11 to 20\n",
      "Clients' weights: [0.22620689655172413, 0.2303448275862069, 0.2868965517241379, 0.25655172413793104]\n",
      "====> i: 1 Server Test Accuracy: [52.38095238095238, 58.45238095238095, 53.627450980392155, 63.666666666666664]\n",
      "====> i: 2 Server Test Accuracy: [57.26190476190476, 60.0, 61.470588235294116, 58.5]\n",
      "====> i: 3 Server Test Accuracy: [56.19047619047619, 57.73809523809524, 59.01960784313726, 59.833333333333336]\n",
      "====> i: 4 Server Test Accuracy: [56.19047619047619, 62.023809523809526, 60.294117647058826, 67.33333333333333]\n",
      "====> i: 5 Server Test Accuracy: [62.142857142857146, 56.07142857142857, 61.1764705882353, 70.0]\n",
      "====> i: 6 Server Test Accuracy: [58.214285714285715, 61.42857142857143, 62.64705882352941, 68.83333333333333]\n",
      "====> i: 7 Server Test Accuracy: [61.19047619047619, 56.07142857142857, 59.6078431372549, 68.66666666666667]\n",
      "====> i: 8 Server Test Accuracy: [59.404761904761905, 60.23809523809524, 62.64705882352941, 69.66666666666667]\n",
      "====> i: 9 Server Test Accuracy: [65.23809523809524, 54.523809523809526, 60.88235294117647, 72.33333333333333]\n",
      "====> i: 10 Server Test Accuracy: [64.16666666666667, 52.023809523809526, 57.94117647058823, 70.66666666666667]\n",
      "Evaluating global model for rounds 11 to 20\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.80      0.66      0.73       300\n",
      "  meningioma       0.47      0.67      0.55       306\n",
      "     notumor       0.83      0.86      0.85       405\n",
      "   pituitary       0.84      0.56      0.67       300\n",
      "\n",
      "    accuracy                           0.70      1311\n",
      "   macro avg       0.73      0.69      0.70      1311\n",
      "weighted avg       0.74      0.70      0.71      1311\n",
      "\n",
      "\n",
      "Accuracy: 70.33%\n",
      "Loss: 1.0294\n",
      "Precision: 0.7410\n",
      "Recall: 0.7033\n",
      "F1 Score: 0.7094\n",
      "Current validation loss: 1.0294\n",
      "Best model updated and saved at: model_results_mu=0.1/best_model_mu=0.1.h5\n",
      "Model saved at: model_results_mu=0.1/global_model_rounds_20_mu=0.1.h5\n",
      "Starting rounds 21 to 30\n",
      "Clients' weights: [0.22620689655172413, 0.2303448275862069, 0.2868965517241379, 0.25655172413793104]\n",
      "====> i: 1 Server Test Accuracy: [63.92857142857143, 60.833333333333336, 63.92156862745098, 73.5]\n",
      "====> i: 2 Server Test Accuracy: [63.80952380952381, 61.42857142857143, 69.01960784313725, 71.83333333333333]\n",
      "====> i: 3 Server Test Accuracy: [60.833333333333336, 62.61904761904762, 60.98039215686274, 71.0]\n",
      "====> i: 4 Server Test Accuracy: [64.76190476190476, 56.54761904761905, 65.3921568627451, 73.33333333333333]\n",
      "====> i: 5 Server Test Accuracy: [66.07142857142857, 59.642857142857146, 62.450980392156865, 74.0]\n",
      "====> i: 6 Server Test Accuracy: [65.11904761904762, 61.30952380952381, 68.33333333333333, 75.5]\n",
      "====> i: 7 Server Test Accuracy: [62.023809523809526, 64.76190476190476, 67.94117647058823, 74.33333333333333]\n",
      "====> i: 8 Server Test Accuracy: [67.61904761904762, 53.80952380952381, 61.568627450980394, 75.66666666666667]\n",
      "====> i: 9 Server Test Accuracy: [66.42857142857143, 64.88095238095238, 66.66666666666667, 76.33333333333333]\n",
      "====> i: 10 Server Test Accuracy: [65.35714285714286, 63.80952380952381, 66.37254901960785, 77.0]\n",
      "Evaluating global model for rounds 21 to 30\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.83      0.74      0.78       300\n",
      "  meningioma       0.66      0.57      0.61       306\n",
      "     notumor       0.83      0.90      0.86       405\n",
      "   pituitary       0.80      0.90      0.85       300\n",
      "\n",
      "    accuracy                           0.79      1311\n",
      "   macro avg       0.78      0.78      0.78      1311\n",
      "weighted avg       0.78      0.79      0.78      1311\n",
      "\n",
      "\n",
      "Accuracy: 78.87%\n",
      "Loss: 0.9582\n",
      "Precision: 0.7841\n",
      "Recall: 0.7887\n",
      "F1 Score: 0.7840\n",
      "Current validation loss: 0.9582\n",
      "Best model updated and saved at: model_results_mu=0.1/best_model_mu=0.1.h5\n",
      "Model saved at: model_results_mu=0.1/global_model_rounds_30_mu=0.1.h5\n",
      "Starting rounds 31 to 40\n",
      "Clients' weights: [0.22620689655172413, 0.2303448275862069, 0.2868965517241379, 0.25655172413793104]\n",
      "====> i: 1 Server Test Accuracy: [68.21428571428571, 59.285714285714285, 67.05882352941177, 78.83333333333333]\n",
      "====> i: 2 Server Test Accuracy: [67.97619047619048, 58.45238095238095, 66.37254901960785, 78.66666666666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "JIT session error: Cannot allocate memory\n",
      "2024-12-08 18:43:37.573079: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at xla_ops.cc:362 : INTERNAL: Failed to compile XLA Runtime program: failed to compile exported function a_inference__update_step_xla_147760478__XlaMustCompile_true_config_proto_6001324581131673121_executor_type_11160318154034397263_.20: Failed to materialize symbols: { (main, { __xla__a_inference__update_step_xla_147760478__XlaMustCompile_true_config_proto_6001324581131673121_executor_type_11160318154034397263_.20 }) }\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed to compile XLA Runtime program: failed to compile exported function a_inference__update_step_xla_147760478__XlaMustCompile_true_config_proto_6001324581131673121_executor_type_11160318154034397263_.20: Failed to materialize symbols: { (main, { __xla__a_inference__update_step_xla_147760478__XlaMustCompile_true_config_proto_6001324581131673121_executor_type_11160318154034397263_.20 }) } [Op:__inference__update_step_xla_147760478]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting rounds \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39mrounds_per_segment\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Train for the specified number of rounds in this segment\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m model, train_loss_f, train_acc_f, test_loss_f, test_acc_f \u001b[38;5;241m=\u001b[39m \u001b[43mFedProx\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTumor_iid_train_dls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrounds_per_segment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTumor_iid_test_dls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Append the metrics to the cumulative lists\u001b[39;00m\n\u001b[1;32m     11\u001b[0m all_train_loss\u001b[38;5;241m.\u001b[39mextend(train_loss_f)\n",
      "Cell \u001b[0;32mIn[3], line 32\u001b[0m, in \u001b[0;36mFedProx\u001b[0;34m(model, training_sets, n_iter, testing_sets, mu, epochs, lr, decay)\u001b[0m\n\u001b[1;32m     29\u001b[0m local_optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39mlr)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Perform local training and track the loss\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m local_loss \u001b[38;5;241m=\u001b[39m \u001b[43mlocal_learning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_sets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_f\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m clients_losses\u001b[38;5;241m.\u001b[39mappend(local_loss)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Track training accuracy for the client\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 70\u001b[0m, in \u001b[0;36mlocal_learning\u001b[0;34m(model, mu, optimizer, train_data, epochs, loss_f)\u001b[0m\n\u001b[1;32m     67\u001b[0m model_0\u001b[38;5;241m.\u001b[39mset_weights(model\u001b[38;5;241m.\u001b[39mget_weights())  \u001b[38;5;66;03m# Set weights to be identical initially\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 70\u001b[0m     local_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_f\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m local_loss\n",
      "Cell \u001b[0;32mIn[2], line 59\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, model_0, mu, optimizer, train_data, loss_f)\u001b[0m\n\u001b[1;32m     57\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     58\u001b[0m     gradients \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[0;32m---> 59\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss \u001b[38;5;241m/\u001b[39m (idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.9/site-packages/keras/optimizers/optimizer.py:1174\u001b[0m, in \u001b[0;36mOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_gradients_aggregation \u001b[38;5;129;01mand\u001b[39;00m experimental_aggregate_gradients:\n\u001b[1;32m   1173\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate_gradients(grads_and_vars)\n\u001b[0;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.9/site-packages/keras/optimizers/optimizer.py:650\u001b[0m, in \u001b[0;36m_BaseOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_weight_decay(trainable_variables)\n\u001b[1;32m    649\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, trainable_variables))\n\u001b[0;32m--> 650\u001b[0m iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_apply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;66;03m# Apply variable constraints after applying gradients.\u001b[39;00m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;129;01min\u001b[39;00m trainable_variables:\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.9/site-packages/keras/optimizers/optimizer.py:1200\u001b[0m, in \u001b[0;36mOptimizer._internal_apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_internal_apply_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, grads_and_vars):\n\u001b[0;32m-> 1200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_merge_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distributed_apply_gradients_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distribution_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/distribute/merge_call_interim.py:51\u001b[0m, in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m  The return value of the `fn` call.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strategy_supports_no_merge_call():\n\u001b[0;32m---> 51\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m distribution_strategy_context\u001b[38;5;241m.\u001b[39mget_replica_context()\u001b[38;5;241m.\u001b[39mmerge_call(\n\u001b[1;32m     54\u001b[0m       fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.9/site-packages/keras/optimizers/optimizer.py:1250\u001b[0m, in \u001b[0;36mOptimizer._distributed_apply_gradients_fn\u001b[0;34m(self, distribution, grads_and_vars, **kwargs)\u001b[0m\n\u001b[1;32m   1247\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_step(grad, var)\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m grad, var \u001b[38;5;129;01min\u001b[39;00m grads_and_vars:\n\u001b[0;32m-> 1250\u001b[0m     \u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_grad_to_update_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_ema:\n\u001b[1;32m   1255\u001b[0m     _, var_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mgrads_and_vars)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2637\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2634\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   2635\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   2636\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 2637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2639\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replica_ctx_update(\n\u001b[1;32m   2640\u001b[0m       var, fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs, group\u001b[38;5;241m=\u001b[39mgroup)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3710\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3707\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, var, fn, args, kwargs, group):\n\u001b[1;32m   3708\u001b[0m   \u001b[38;5;66;03m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[1;32m   3709\u001b[0m   \u001b[38;5;66;03m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[0;32m-> 3710\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_non_slot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3716\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   3712\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_non_slot\u001b[39m(\u001b[38;5;28mself\u001b[39m, colocate_with, fn, args, kwargs, should_group):\n\u001b[1;32m   3713\u001b[0m   \u001b[38;5;66;03m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[1;32m   3714\u001b[0m   \u001b[38;5;66;03m# once that value is used for something.\u001b[39;00m\n\u001b[1;32m   3715\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[0;32m-> 3716\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3717\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_group:\n\u001b[1;32m   3718\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:595\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    594\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mUNSPECIFIED):\n\u001b[0;32m--> 595\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.9/site-packages/keras/optimizers/optimizer.py:1245\u001b[0m, in \u001b[0;36mOptimizer._distributed_apply_gradients_fn.<locals>.apply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m   1243\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_grad_to_update_var\u001b[39m(var, grad):\n\u001b[1;32m   1244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit_compile:\n\u001b[0;32m-> 1245\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_step_xla\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_var_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1247\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_step(grad, var)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed to compile XLA Runtime program: failed to compile exported function a_inference__update_step_xla_147760478__XlaMustCompile_true_config_proto_6001324581131673121_executor_type_11160318154034397263_.20: Failed to materialize symbols: { (main, { __xla__a_inference__update_step_xla_147760478__XlaMustCompile_true_config_proto_6001324581131673121_executor_type_11160318154034397263_.20 }) } [Op:__inference__update_step_xla_147760478]"
     ]
    }
   ],
   "source": [
    "# Function for FedProx training in segments\n",
    "for i in range(0, n_iter, rounds_per_segment):\n",
    "    print(f\"Starting rounds {i+1} to {i+rounds_per_segment}\")\n",
    "    \n",
    "    # Train for the specified number of rounds in this segment\n",
    "    model, train_loss_f, train_acc_f, test_loss_f, test_acc_f = FedProx(\n",
    "        model, Tumor_iid_train_dls, rounds_per_segment, Tumor_iid_test_dls, mu=mu, epochs=epochs, lr=lr\n",
    "    )\n",
    "    \n",
    "    # Append the metrics to the cumulative lists\n",
    "    all_train_loss.extend(train_loss_f)\n",
    "    all_train_acc.extend(train_acc_f)\n",
    "    all_test_loss.extend(test_loss_f)\n",
    "    all_test_acc.extend(test_acc_f)\n",
    "    \n",
    "     # Test the saved global model on the testing dataset\n",
    "    print(f\"Evaluating global model for rounds {i+1} to {i+rounds_per_segment}\")\n",
    "    current_metric = evaluate_global_model(model, test_loader, output_file=f'{MODEL_PATH}Global_Model_Results_mu={mu}.txt')\n",
    "    \n",
    "    \n",
    "    # Check for early stopping based on validation loss\n",
    "    # current_metric = test_loss_f[-1][-1]  # Use the most recent validation loss\n",
    "    print(f\"Current validation loss: {current_metric:.4f}\")\n",
    "    \n",
    "    if best_metric is None or current_metric < best_metric:  # Improvement check\n",
    "        best_metric = current_metric\n",
    "        no_improve_rounds = 0  # Reset counter\n",
    "        # Save the best model\n",
    "        best_model_path = f'{MODEL_PATH}best_model_mu={mu}_{i+rounds_per_segment}_rounds.h5'\n",
    "        model.save(best_model_path)\n",
    "        print(f\"Best model updated and saved at: {best_model_path}\")\n",
    "    else:\n",
    "        no_improve_rounds += 10\n",
    "        print(f\"No improvement for {no_improve_rounds} rounds. Best validation loss: {best_metric:.4f}\")\n",
    "\n",
    "    # Save the model at the end of each segment\n",
    "    segment_model_path = f'{MODEL_PATH}global_model_rounds_{i+rounds_per_segment}_mu={mu}.h5'\n",
    "    model.save(segment_model_path)\n",
    "    print(f\"Model saved at: {segment_model_path}\")\n",
    "    \n",
    "    \n",
    "    # Save the data to the file\n",
    "    # output_file = f'{MODEL_PATH}results-mu={mu}_{len(train_loss_f)}_rounds.txt'\n",
    "    # save_history_to_file(output_file, train_loss_f, train_acc_f, test_loss_f, test_acc_f)\n",
    "    \n",
    "    if no_improve_rounds >= patience:  # Early stopping condition\n",
    "        print(\"Early stopping triggered. Training stopped.\")\n",
    "        break\n",
    "    \n",
    "    # Reload the model to ensure continuity for the next segment\n",
    "    model = tf.keras.models.load_model(segment_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "730a7c9a-e0b9-4b91-be54-f648e2de2cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-09 12:09:47.615722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31132 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('model_results_mu=0.1/global_model_rounds_30_mu=0.1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdab2446-4320-44bf-a49e-c16ecd7c7aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting rounds 31 to 40\n",
      "Clients' weights: [0.22620689655172413, 0.2303448275862069, 0.2868965517241379, 0.25655172413793104]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-09 12:10:01.132680: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n",
      "2024-12-09 12:10:04.735953: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x22fa03c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-09 12:10:04.735984: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-12-09 12:10:04.811454: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7fb0d8193310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7fb0d8193310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "====> i: 1 Server Test Accuracy: [68.57142857142857, 64.88095238095238, 69.31372549019608, 78.83333333333333]\n",
      "====> i: 2 Server Test Accuracy: [65.83333333333333, 65.83333333333333, 66.07843137254902, 78.5]\n",
      "====> i: 3 Server Test Accuracy: [67.97619047619048, 61.30952380952381, 69.50980392156863, 76.33333333333333]\n",
      "====> i: 4 Server Test Accuracy: [67.38095238095238, 61.42857142857143, 67.84313725490196, 78.33333333333333]\n",
      "====> i: 5 Server Test Accuracy: [64.4047619047619, 53.92857142857143, 59.31372549019608, 71.16666666666667]\n",
      "====> i: 6 Server Test Accuracy: [67.38095238095238, 64.4047619047619, 68.33333333333333, 79.0]\n",
      "====> i: 7 Server Test Accuracy: [68.0952380952381, 64.4047619047619, 67.54901960784314, 79.83333333333333]\n",
      "====> i: 8 Server Test Accuracy: [69.16666666666667, 65.83333333333333, 68.33333333333333, 79.33333333333333]\n",
      "====> i: 9 Server Test Accuracy: [69.28571428571429, 59.88095238095238, 66.86274509803921, 79.83333333333333]\n",
      "====> i: 10 Server Test Accuracy: [70.0, 63.095238095238095, 70.29411764705883, 81.66666666666667]\n",
      "Evaluating global model for rounds 31 to 40\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.81      0.75      0.78       300\n",
      "  meningioma       0.66      0.60      0.63       306\n",
      "     notumor       0.86      0.89      0.87       405\n",
      "   pituitary       0.81      0.91      0.85       300\n",
      "\n",
      "    accuracy                           0.79      1311\n",
      "   macro avg       0.78      0.79      0.78      1311\n",
      "weighted avg       0.79      0.79      0.79      1311\n",
      "\n",
      "\n",
      "Accuracy: 79.33%\n",
      "Loss: 0.9451\n",
      "Precision: 0.7899\n",
      "Recall: 0.7933\n",
      "F1 Score: 0.7902\n",
      "Current validation loss: 0.9451\n",
      "Best model updated and saved at: model_results_mu=0.1/best_model_mu=0.1_40_rounds.h5\n",
      "Model saved at: model_results_mu=0.1/global_model_rounds_40_mu=0.1.h5\n",
      "Starting rounds 41 to 50\n",
      "Clients' weights: [0.22620689655172413, 0.2303448275862069, 0.2868965517241379, 0.25655172413793104]\n",
      "====> i: 1 Server Test Accuracy: [68.45238095238095, 61.42857142857143, 68.23529411764706, 80.5]\n",
      "====> i: 2 Server Test Accuracy: [70.83333333333333, 60.357142857142854, 69.90196078431373, 81.83333333333333]\n",
      "====> i: 3 Server Test Accuracy: [70.95238095238095, 60.23809523809524, 68.03921568627452, 81.66666666666667]\n",
      "====> i: 4 Server Test Accuracy: [71.07142857142857, 66.30952380952381, 71.76470588235294, 82.16666666666667]\n",
      "====> i: 5 Server Test Accuracy: [71.66666666666667, 62.976190476190474, 69.80392156862744, 82.66666666666667]\n",
      "====> i: 6 Server Test Accuracy: [70.47619047619048, 63.45238095238095, 70.09803921568627, 82.66666666666667]\n",
      "====> i: 7 Server Test Accuracy: [74.76190476190476, 64.16666666666667, 71.66666666666667, 82.66666666666667]\n",
      "====> i: 8 Server Test Accuracy: [71.30952380952381, 63.57142857142857, 71.96078431372548, 83.83333333333333]\n",
      "====> i: 9 Server Test Accuracy: [70.5952380952381, 66.78571428571429, 72.94117647058823, 84.83333333333333]\n",
      "====> i: 10 Server Test Accuracy: [69.16666666666667, 69.4047619047619, 70.19607843137256, 80.16666666666667]\n",
      "Evaluating global model for rounds 41 to 50\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.80      0.82      0.81       300\n",
      "  meningioma       0.74      0.53      0.62       306\n",
      "     notumor       0.82      0.95      0.88       405\n",
      "   pituitary       0.85      0.90      0.87       300\n",
      "\n",
      "    accuracy                           0.81      1311\n",
      "   macro avg       0.80      0.80      0.79      1311\n",
      "weighted avg       0.80      0.81      0.80      1311\n",
      "\n",
      "\n",
      "Accuracy: 80.93%\n",
      "Loss: 0.9325\n",
      "Precision: 0.8038\n",
      "Recall: 0.8093\n",
      "F1 Score: 0.8008\n",
      "Current validation loss: 0.9325\n",
      "Best model updated and saved at: model_results_mu=0.1/best_model_mu=0.1_50_rounds.h5\n",
      "Model saved at: model_results_mu=0.1/global_model_rounds_50_mu=0.1.h5\n",
      "Starting rounds 51 to 60\n",
      "Clients' weights: [0.22620689655172413, 0.2303448275862069, 0.2868965517241379, 0.25655172413793104]\n",
      "====> i: 1 Server Test Accuracy: [73.21428571428571, 65.5952380952381, 71.86274509803921, 86.5]\n",
      "====> i: 2 Server Test Accuracy: [72.02380952380952, 67.73809523809524, 73.92156862745098, 83.66666666666667]\n",
      "====> i: 3 Server Test Accuracy: [70.71428571428571, 69.04761904761905, 71.37254901960785, 83.83333333333333]\n",
      "====> i: 4 Server Test Accuracy: [71.78571428571429, 63.333333333333336, 68.52941176470588, 84.83333333333333]\n",
      "====> i: 5 Server Test Accuracy: [67.73809523809524, 67.73809523809524, 69.41176470588235, 81.5]\n",
      "====> i: 6 Server Test Accuracy: [72.5, 64.4047619047619, 71.56862745098039, 83.83333333333333]\n",
      "====> i: 7 Server Test Accuracy: [73.57142857142857, 67.38095238095238, 72.84313725490196, 87.16666666666667]\n",
      "====> i: 8 Server Test Accuracy: [54.88095238095238, 62.023809523809526, 56.1764705882353, 65.16666666666667]\n",
      "====> i: 9 Server Test Accuracy: [70.11904761904762, 66.9047619047619, 70.19607843137256, 81.83333333333333]\n",
      "====> i: 10 Server Test Accuracy: [68.80952380952381, 68.0952380952381, 70.3921568627451, 82.0]\n",
      "Evaluating global model for rounds 51 to 60\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.76      0.87      0.81       300\n",
      "  meningioma       0.76      0.55      0.64       306\n",
      "     notumor       0.85      0.93      0.89       405\n",
      "   pituitary       0.87      0.88      0.87       300\n",
      "\n",
      "    accuracy                           0.82      1311\n",
      "   macro avg       0.81      0.81      0.80      1311\n",
      "weighted avg       0.81      0.82      0.81      1311\n",
      "\n",
      "\n",
      "Accuracy: 81.62%\n",
      "Loss: 0.9321\n",
      "Precision: 0.8135\n",
      "Recall: 0.8162\n",
      "F1 Score: 0.8091\n",
      "Current validation loss: 0.9321\n",
      "Best model updated and saved at: model_results_mu=0.1/best_model_mu=0.1_60_rounds.h5\n",
      "Model saved at: model_results_mu=0.1/global_model_rounds_60_mu=0.1.h5\n",
      "Starting rounds 61 to 70\n",
      "Clients' weights: [0.22620689655172413, 0.2303448275862069, 0.2868965517241379, 0.25655172413793104]\n",
      "====> i: 1 Server Test Accuracy: [74.04761904761905, 64.52380952380952, 71.27450980392157, 84.33333333333333]\n",
      "====> i: 2 Server Test Accuracy: [72.26190476190476, 67.14285714285714, 74.6078431372549, 83.33333333333333]\n"
     ]
    }
   ],
   "source": [
    "# Function for FedProx training in segments\n",
    "for i in range(30, n_iter, rounds_per_segment):\n",
    "    print(f\"Starting rounds {i+1} to {i+rounds_per_segment}\")\n",
    "    \n",
    "    # Train for the specified number of rounds in this segment\n",
    "    model, train_loss_f, train_acc_f, test_loss_f, test_acc_f = FedProx(\n",
    "        model, Tumor_iid_train_dls, rounds_per_segment, Tumor_iid_test_dls, mu=mu, epochs=epochs, lr=lr\n",
    "    )\n",
    "    \n",
    "    # Append the metrics to the cumulative lists\n",
    "    all_train_loss.extend(train_loss_f)\n",
    "    all_train_acc.extend(train_acc_f)\n",
    "    all_test_loss.extend(test_loss_f)\n",
    "    all_test_acc.extend(test_acc_f)\n",
    "    \n",
    "     # Test the saved global model on the testing dataset\n",
    "    print(f\"Evaluating global model for rounds {i+1} to {i+rounds_per_segment}\")\n",
    "    current_metric = evaluate_global_model(model, test_loader, output_file=f'{MODEL_PATH}Global_Model_Results_mu={mu}.txt')\n",
    "    \n",
    "    \n",
    "    # Check for early stopping based on validation loss\n",
    "    # current_metric = test_loss_f[-1][-1]  # Use the most recent validation loss\n",
    "    print(f\"Current validation loss: {current_metric:.4f}\")\n",
    "    \n",
    "    if best_metric is None or current_metric < best_metric:  # Improvement check\n",
    "        best_metric = current_metric\n",
    "        no_improve_rounds = 0  # Reset counter\n",
    "        # Save the best model\n",
    "        best_model_path = f'{MODEL_PATH}best_model_mu={mu}_{i+rounds_per_segment}_rounds.h5'\n",
    "        model.save(best_model_path)\n",
    "        print(f\"Best model updated and saved at: {best_model_path}\")\n",
    "    else:\n",
    "        no_improve_rounds += 10\n",
    "        print(f\"No improvement for {no_improve_rounds} rounds. Best validation loss: {best_metric:.4f}\")\n",
    "\n",
    "    # Save the model at the end of each segment\n",
    "    segment_model_path = f'{MODEL_PATH}global_model_rounds_{i+rounds_per_segment}_mu={mu}.h5'\n",
    "    model.save(segment_model_path)\n",
    "    print(f\"Model saved at: {segment_model_path}\")\n",
    "    \n",
    "    \n",
    "    # Save the data to the file\n",
    "    # output_file = f'{MODEL_PATH}results-mu={mu}_{len(train_loss_f)}_rounds.txt'\n",
    "    # save_history_to_file(output_file, train_loss_f, train_acc_f, test_loss_f, test_acc_f)\n",
    "    \n",
    "    if no_improve_rounds >= patience:  # Early stopping condition\n",
    "        print(\"Early stopping triggered. Training stopped.\")\n",
    "        break\n",
    "    \n",
    "    # Reload the model to ensure continuity for the next segment\n",
    "    model = tf.keras.models.load_model(segment_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "239a9ee6-1a75-4830-9386-113090538364",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 11:28:05.750831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31132 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('model_results_mu=0.1/global_model_rounds_60_mu=0.1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874f777a-3a58-4aa8-b91f-2b3398031ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting rounds 61 to 70\n",
      "Clients' weights: [0.22620689655172413, 0.2303448275862069, 0.2868965517241379, 0.25655172413793104]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 11:28:38.630418: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n",
      "2024-12-10 11:28:41.681007: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x22ff6070 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-10 11:28:41.681038: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-12-10 11:28:41.753200: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7ff840021700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7ff840021700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "====> i: 1 Server Test Accuracy: [72.73809523809524, 62.857142857142854, 69.70588235294117, 83.66666666666667]\n",
      "====> i: 2 Server Test Accuracy: [73.69047619047619, 65.0, 69.6078431372549, 84.66666666666667]\n",
      "====> i: 3 Server Test Accuracy: [73.21428571428571, 66.19047619047619, 69.50980392156863, 86.33333333333333]\n",
      "====> i: 4 Server Test Accuracy: [73.21428571428571, 65.23809523809524, 70.58823529411765, 85.66666666666667]\n",
      "====> i: 5 Server Test Accuracy: [72.73809523809524, 61.785714285714285, 67.6470588235294, 83.33333333333333]\n",
      "====> i: 6 Server Test Accuracy: [72.02380952380952, 66.9047619047619, 70.58823529411765, 84.83333333333333]\n",
      "====> i: 7 Server Test Accuracy: [70.0, 55.357142857142854, 60.09803921568628, 77.66666666666667]\n",
      "====> i: 8 Server Test Accuracy: [71.42857142857143, 66.66666666666667, 71.17647058823529, 85.5]\n",
      "====> i: 9 Server Test Accuracy: [71.42857142857143, 67.14285714285714, 70.09803921568627, 84.33333333333333]\n",
      "====> i: 10 Server Test Accuracy: [73.69047619047619, 68.57142857142857, 75.49019607843137, 85.33333333333333]\n",
      "Evaluating global model for rounds 61 to 70\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.86      0.79      0.82       300\n",
      "  meningioma       0.73      0.59      0.65       306\n",
      "     notumor       0.88      0.91      0.89       405\n",
      "   pituitary       0.78      0.96      0.86       300\n",
      "\n",
      "    accuracy                           0.82      1311\n",
      "   macro avg       0.81      0.81      0.81      1311\n",
      "weighted avg       0.82      0.82      0.81      1311\n",
      "\n",
      "\n",
      "Accuracy: 81.92%\n",
      "Loss: 0.9223\n",
      "Precision: 0.8173\n",
      "Recall: 0.8192\n",
      "F1 Score: 0.8139\n",
      "Current validation loss: 0.9223\n",
      "Best model updated and saved at: model_results_mu=0.1/best_model_mu=0.1_70_rounds.h5\n",
      "Model saved at: model_results_mu=0.1/global_model_rounds_70_mu=0.1.h5\n",
      "Starting rounds 71 to 80\n",
      "Clients' weights: [0.22620689655172413, 0.2303448275862069, 0.2868965517241379, 0.25655172413793104]\n",
      "====> i: 1 Server Test Accuracy: [72.85714285714286, 70.47619047619048, 74.01960784313725, 86.5]\n",
      "====> i: 2 Server Test Accuracy: [71.19047619047619, 61.19047619047619, 67.15686274509804, 81.33333333333333]\n",
      "====> i: 3 Server Test Accuracy: [71.54761904761905, 67.14285714285714, 70.0, 83.5]\n",
      "====> i: 4 Server Test Accuracy: [72.5, 65.23809523809524, 72.94117647058823, 80.33333333333333]\n",
      "====> i: 5 Server Test Accuracy: [71.78571428571429, 64.52380952380952, 69.31372549019608, 84.0]\n",
      "====> i: 6 Server Test Accuracy: [74.4047619047619, 67.61904761904762, 73.72549019607843, 85.5]\n",
      "====> i: 7 Server Test Accuracy: [73.0952380952381, 64.28571428571429, 70.0, 84.83333333333333]\n",
      "====> i: 8 Server Test Accuracy: [73.33333333333333, 66.07142857142857, 70.0, 85.66666666666667]\n",
      "====> i: 9 Server Test Accuracy: [74.4047619047619, 67.14285714285714, 72.05882352941177, 86.16666666666667]\n",
      "====> i: 10 Server Test Accuracy: [74.88095238095238, 64.64285714285714, 69.6078431372549, 84.66666666666667]\n",
      "Evaluating global model for rounds 71 to 80\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.91      0.72      0.81       300\n",
      "  meningioma       0.68      0.72      0.70       306\n",
      "     notumor       0.87      0.94      0.91       405\n",
      "   pituitary       0.88      0.92      0.90       300\n",
      "\n",
      "    accuracy                           0.84      1311\n",
      "   macro avg       0.84      0.83      0.83      1311\n",
      "weighted avg       0.84      0.84      0.83      1311\n",
      "\n",
      "\n",
      "Accuracy: 83.52%\n",
      "Loss: 0.9049\n",
      "Precision: 0.8391\n",
      "Recall: 0.8352\n",
      "F1 Score: 0.8342\n",
      "Current validation loss: 0.9049\n",
      "Best model updated and saved at: model_results_mu=0.1/best_model_mu=0.1_80_rounds.h5\n",
      "Model saved at: model_results_mu=0.1/global_model_rounds_80_mu=0.1.h5\n",
      "Starting rounds 81 to 90\n",
      "Clients' weights: [0.22620689655172413, 0.2303448275862069, 0.2868965517241379, 0.25655172413793104]\n",
      "====> i: 1 Server Test Accuracy: [72.85714285714286, 69.76190476190476, 74.11764705882354, 85.83333333333333]\n",
      "====> i: 2 Server Test Accuracy: [72.61904761904762, 71.07142857142857, 73.33333333333333, 84.16666666666667]\n",
      "====> i: 3 Server Test Accuracy: [71.9047619047619, 60.714285714285715, 64.41176470588235, 81.5]\n",
      "====> i: 4 Server Test Accuracy: [71.30952380952381, 69.4047619047619, 70.68627450980392, 83.0]\n",
      "====> i: 5 Server Test Accuracy: [72.61904761904762, 70.0, 72.45098039215686, 85.0]\n",
      "====> i: 6 Server Test Accuracy: [72.26190476190476, 69.16666666666667, 72.84313725490196, 83.66666666666667]\n",
      "====> i: 7 Server Test Accuracy: [74.88095238095238, 67.02380952380952, 72.3529411764706, 84.66666666666667]\n",
      "====> i: 8 Server Test Accuracy: [72.38095238095238, 66.42857142857143, 70.68627450980392, 83.83333333333333]\n",
      "====> i: 9 Server Test Accuracy: [68.92857142857143, 51.54761904761905, 60.3921568627451, 69.66666666666667]\n",
      "====> i: 10 Server Test Accuracy: [73.69047619047619, 60.11904761904762, 65.7843137254902, 79.66666666666667]\n",
      "Evaluating global model for rounds 81 to 90\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.98      0.66      0.79       300\n",
      "  meningioma       0.68      0.71      0.69       306\n",
      "     notumor       0.88      0.95      0.91       405\n",
      "   pituitary       0.83      0.98      0.90       300\n",
      "\n",
      "    accuracy                           0.83      1311\n",
      "   macro avg       0.84      0.82      0.82      1311\n",
      "weighted avg       0.85      0.83      0.83      1311\n",
      "\n",
      "\n",
      "Accuracy: 83.37%\n",
      "Loss: 0.9071\n",
      "Precision: 0.8456\n",
      "Recall: 0.8337\n",
      "F1 Score: 0.8301\n",
      "Current validation loss: 0.9071\n",
      "No improvement for 10 rounds. Best validation loss: 0.9049\n",
      "Model saved at: model_results_mu=0.1/global_model_rounds_90_mu=0.1.h5\n",
      "Starting rounds 91 to 100\n",
      "Clients' weights: [0.22620689655172413, 0.2303448275862069, 0.2868965517241379, 0.25655172413793104]\n",
      "====> i: 1 Server Test Accuracy: [73.21428571428571, 68.0952380952381, 72.05882352941177, 85.0]\n",
      "====> i: 2 Server Test Accuracy: [75.95238095238095, 66.42857142857143, 74.41176470588235, 83.33333333333333]\n"
     ]
    }
   ],
   "source": [
    "# Function for FedProx training in segments\n",
    "for i in range(60, n_iter, rounds_per_segment):\n",
    "    print(f\"Starting rounds {i+1} to {i+rounds_per_segment}\")\n",
    "    \n",
    "    # Train for the specified number of rounds in this segment\n",
    "    model, train_loss_f, train_acc_f, test_loss_f, test_acc_f = FedProx(\n",
    "        model, Tumor_iid_train_dls, rounds_per_segment, Tumor_iid_test_dls, mu=mu, epochs=epochs, lr=lr\n",
    "    )\n",
    "    \n",
    "    # Append the metrics to the cumulative lists\n",
    "    all_train_loss.extend(train_loss_f)\n",
    "    all_train_acc.extend(train_acc_f)\n",
    "    all_test_loss.extend(test_loss_f)\n",
    "    all_test_acc.extend(test_acc_f)\n",
    "    \n",
    "     # Test the saved global model on the testing dataset\n",
    "    print(f\"Evaluating global model for rounds {i+1} to {i+rounds_per_segment}\")\n",
    "    current_metric = evaluate_global_model(model, test_loader, output_file=f'{MODEL_PATH}Global_Model_Results_mu={mu}.txt')\n",
    "    \n",
    "    \n",
    "    # Check for early stopping based on validation loss\n",
    "    # current_metric = test_loss_f[-1][-1]  # Use the most recent validation loss\n",
    "    print(f\"Current validation loss: {current_metric:.4f}\")\n",
    "    \n",
    "    if best_metric is None or current_metric < best_metric:  # Improvement check\n",
    "        best_metric = current_metric\n",
    "        no_improve_rounds = 0  # Reset counter\n",
    "        # Save the best model\n",
    "        best_model_path = f'{MODEL_PATH}best_model_mu={mu}_{i+rounds_per_segment}_rounds.h5'\n",
    "        model.save(best_model_path)\n",
    "        print(f\"Best model updated and saved at: {best_model_path}\")\n",
    "    else:\n",
    "        no_improve_rounds += 10\n",
    "        print(f\"No improvement for {no_improve_rounds} rounds. Best validation loss: {best_metric:.4f}\")\n",
    "\n",
    "    # Save the model at the end of each segment\n",
    "    segment_model_path = f'{MODEL_PATH}global_model_rounds_{i+rounds_per_segment}_mu={mu}.h5'\n",
    "    model.save(segment_model_path)\n",
    "    print(f\"Model saved at: {segment_model_path}\")\n",
    "    \n",
    "    \n",
    "    # Save the data to the file\n",
    "    # output_file = f'{MODEL_PATH}results-mu={mu}_{len(train_loss_f)}_rounds.txt'\n",
    "    # save_history_to_file(output_file, train_loss_f, train_acc_f, test_loss_f, test_acc_f)\n",
    "    \n",
    "    if no_improve_rounds >= patience:  # Early stopping condition\n",
    "        print(\"Early stopping triggered. Training stopped.\")\n",
    "        break\n",
    "    \n",
    "    # Reload the model to ensure continuity for the next segment\n",
    "    model = tf.keras.models.load_model(segment_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5c4d5f2-f483-4387-9b1a-ddab041af80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 04:40:38.834050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31132 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('model_results_mu=0.1/global_model_rounds_90_mu=0.1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89d77a2b-8eea-4f25-9c80-23245c8ccb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting rounds 91 to 100\n",
      "Clients' weights: [0.22620689655172413, 0.2303448275862069, 0.2868965517241379, 0.25655172413793104]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 04:41:15.306686: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n",
      "2024-12-11 04:41:18.347203: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x2373c460 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-11 04:41:18.347235: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-12-11 04:41:18.418707: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f28c47581f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f28c47581f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "====> i: 1 Server Test Accuracy: [73.92857142857143, 64.04761904761905, 65.49019607843137, 83.33333333333333]\n",
      "====> i: 2 Server Test Accuracy: [73.21428571428571, 69.88095238095238, 73.03921568627452, 83.0]\n",
      "====> i: 3 Server Test Accuracy: [68.57142857142857, 70.0, 69.2156862745098, 81.33333333333333]\n",
      "====> i: 4 Server Test Accuracy: [74.28571428571429, 66.07142857142857, 68.72549019607843, 82.5]\n",
      "====> i: 5 Server Test Accuracy: [70.47619047619048, 69.76190476190476, 70.3921568627451, 82.5]\n",
      "====> i: 6 Server Test Accuracy: [73.21428571428571, 67.85714285714286, 71.17647058823529, 83.16666666666667]\n",
      "====> i: 7 Server Test Accuracy: [74.4047619047619, 70.35714285714286, 74.50980392156863, 79.0]\n",
      "====> i: 8 Server Test Accuracy: [72.73809523809524, 62.023809523809526, 66.37254901960785, 82.33333333333333]\n",
      "====> i: 9 Server Test Accuracy: [72.97619047619048, 67.38095238095238, 71.17647058823529, 84.33333333333333]\n",
      "====> i: 10 Server Test Accuracy: [60.833333333333336, 63.095238095238095, 62.94117647058823, 67.66666666666667]\n",
      "Evaluating global model for rounds 91 to 100\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.53      0.99      0.69       300\n",
      "  meningioma       0.80      0.24      0.37       306\n",
      "     notumor       0.89      0.89      0.89       405\n",
      "   pituitary       0.88      0.74      0.81       300\n",
      "\n",
      "    accuracy                           0.73      1311\n",
      "   macro avg       0.78      0.72      0.69      1311\n",
      "weighted avg       0.79      0.73      0.70      1311\n",
      "\n",
      "\n",
      "Accuracy: 72.77%\n",
      "Loss: 1.0097\n",
      "Precision: 0.7866\n",
      "Recall: 0.7277\n",
      "F1 Score: 0.7043\n",
      "Current validation loss: 1.0097\n",
      "No improvement for 20 rounds. Best validation loss: 0.9049\n",
      "Model saved at: model_results_mu=0.1/global_model_rounds_100_mu=0.1.h5\n",
      "Early stopping triggered. Training stopped.\n"
     ]
    }
   ],
   "source": [
    "# Function for FedProx training in segments\n",
    "for i in range(90, n_iter, rounds_per_segment):\n",
    "    print(f\"Starting rounds {i+1} to {i+rounds_per_segment}\")\n",
    "    \n",
    "    # Train for the specified number of rounds in this segment\n",
    "    model, train_loss_f, train_acc_f, test_loss_f, test_acc_f = FedProx(\n",
    "        model, Tumor_iid_train_dls, rounds_per_segment, Tumor_iid_test_dls, mu=mu, epochs=epochs, lr=lr\n",
    "    )\n",
    "    \n",
    "    # Append the metrics to the cumulative lists\n",
    "    all_train_loss.extend(train_loss_f)\n",
    "    all_train_acc.extend(train_acc_f)\n",
    "    all_test_loss.extend(test_loss_f)\n",
    "    all_test_acc.extend(test_acc_f)\n",
    "    \n",
    "     # Test the saved global model on the testing dataset\n",
    "    print(f\"Evaluating global model for rounds {i+1} to {i+rounds_per_segment}\")\n",
    "    current_metric = evaluate_global_model(model, test_loader, output_file=f'{MODEL_PATH}Global_Model_Results_mu={mu}.txt')\n",
    "    \n",
    "    \n",
    "    # Check for early stopping based on validation loss\n",
    "    # current_metric = test_loss_f[-1][-1]  # Use the most recent validation loss\n",
    "    print(f\"Current validation loss: {current_metric:.4f}\")\n",
    "    \n",
    "    if best_metric is None or current_metric < best_metric:  # Improvement check\n",
    "        best_metric = current_metric\n",
    "        no_improve_rounds = 0  # Reset counter\n",
    "        # Save the best model\n",
    "        best_model_path = f'{MODEL_PATH}best_model_mu={mu}_{i+rounds_per_segment}_rounds.h5'\n",
    "        model.save(best_model_path)\n",
    "        print(f\"Best model updated and saved at: {best_model_path}\")\n",
    "    else:\n",
    "        no_improve_rounds += 10\n",
    "        print(f\"No improvement for {no_improve_rounds} rounds. Best validation loss: {best_metric:.4f}\")\n",
    "\n",
    "    # Save the model at the end of each segment\n",
    "    segment_model_path = f'{MODEL_PATH}global_model_rounds_{i+rounds_per_segment}_mu={mu}.h5'\n",
    "    model.save(segment_model_path)\n",
    "    print(f\"Model saved at: {segment_model_path}\")\n",
    "    \n",
    "    \n",
    "    # Save the data to the file\n",
    "    # output_file = f'{MODEL_PATH}results-mu={mu}_{len(train_loss_f)}_rounds.txt'\n",
    "    # save_history_to_file(output_file, train_loss_f, train_acc_f, test_loss_f, test_acc_f)\n",
    "    \n",
    "    if no_improve_rounds >= patience:  # Early stopping condition\n",
    "        print(\"Early stopping triggered. Training stopped.\")\n",
    "        break\n",
    "    \n",
    "    # Reload the model to ensure continuity for the next segment\n",
    "    model = tf.keras.models.load_model(segment_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaf5eb2-fb47-4cb7-8a42-0a781464678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cumulative history to a file after all rounds are complete\n",
    "train_loss = all_train_loss[-100:]  # Adjusted to reflect 30 rounds for rounds 51 to 80\n",
    "train_acc = all_train_acc[-100:]\n",
    "test_loss = all_test_loss[-100:]\n",
    "test_acc = all_test_acc[-100:]\n",
    "\n",
    "# File to save the results\n",
    "mu=0.1\n",
    "output_file = f'{MODEL_PATH}results-mu={mu}_{len(train_loss)}_rounds.txt'\n",
    "\n",
    "# Save the data to the file\n",
    "save_history_to_file(output_file, train_loss, train_acc, test_loss, test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c08a858-daac-400f-8590-d4fe02749e60",
   "metadata": {},
   "source": [
    "# Load the trained model to test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a03a78f-25d8-4804-81c1-7251fe0cbd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 08:10:26.688269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31134 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "mu=0.1\n",
    "MODEL_PATH = f'model_results_mu=0.1/global_model_rounds_100_mu=0.1.h5'\n",
    "model = tf.keras.models.load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28d64d0d-1d4b-4cc1-9610-6fb559614cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 08:10:30.376300: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.53      0.99      0.69       300\n",
      "  meningioma       0.80      0.24      0.37       306\n",
      "     notumor       0.89      0.89      0.89       405\n",
      "   pituitary       0.88      0.74      0.81       300\n",
      "\n",
      "    accuracy                           0.73      1311\n",
      "   macro avg       0.78      0.72      0.69      1311\n",
      "weighted avg       0.79      0.73      0.70      1311\n",
      "\n",
      "\n",
      "Accuracy: 72.77%\n",
      "Loss: 1.0097\n",
      "Precision: 0.7866\n",
      "Recall: 0.7277\n",
      "F1 Score: 0.7043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.009693821755851"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_global_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed821c2-9775-433f-a49b-d74780dd2169",
   "metadata": {},
   "source": [
    "# To save the plots of performance metrics (need to take manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f189d14-5ff7-4890-aee5-bf0c14ba920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Data: Metrics for different rounds (example values, replace with actual data)\n",
    "rounds = [20, 60, 80, 100]\n",
    "accuracies = [87.49, 90.69, 90.92, 91.46]\n",
    "losses = [0.8670, 0.8367, 0.8369, 0.8288]\n",
    "recalls = [87.49, 90.69, 90.92, 91.46]  # Same as accuracies since recall = accuracy in weighted average here\n",
    "f1_scores = [87.19, 90.66, 90.88, 91.41]\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(rounds, accuracies, marker='o', linestyle='-', color='b', label='Accuracy')\n",
    "plt.title('Accuracy of global model with mu=0.1')\n",
    "plt.xlabel('Rounds')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xticks(rounds)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig('model_results_mu=0.1/accuracy_over_rounds.png')  # Save plot as PNG\n",
    "plt.close()  # Close the figure to avoid overlap\n",
    "\n",
    "# Plot Loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(rounds, losses, marker='o', linestyle='-', color='r', label='Loss')\n",
    "plt.title('Loss of global model with mu=0.1')\n",
    "plt.xlabel('Rounds')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(rounds)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig('model_results_mu=0.1/loss_over_rounds.png')  # Save plot as PNG\n",
    "plt.close()\n",
    "\n",
    "# Plot Recall\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(rounds, recalls, marker='o', linestyle='-', color='g', label='Recall')\n",
    "plt.title('Recall of global model with mu=0.1')\n",
    "plt.xlabel('Rounds')\n",
    "plt.ylabel('Recall (%)')\n",
    "plt.xticks(rounds)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig('model_results_mu=0.1/recall_over_rounds.png')  # Save plot as PNG\n",
    "plt.close()\n",
    "\n",
    "# Plot F1 Score\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(rounds, f1_scores, marker='o', linestyle='-', color='m', label='F1 Score')\n",
    "plt.title('F1 of global model with mu=0.1')\n",
    "plt.xlabel('Rounds')\n",
    "plt.ylabel('F1 Score (%)')\n",
    "plt.xticks(rounds)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig('model_results_mu=0.1/f1_score_over_rounds.png')  # Save plot as PNG\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5a3bb6-3d7f-48b1-bc0e-525481ed94dd",
   "metadata": {},
   "source": [
    "# to check how good the model to predict the class of a random image from testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2de34a-7b24-4e5e-b881-8182da8ed04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class names\n",
    "class_names = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "\n",
    "# Function to predict the class of a single image\n",
    "def predict_image(image_path, model):\n",
    "    # Load and preprocess the image\n",
    "    image = load_img(image_path, target_size=(224, 224))  # Resize to 224x224\n",
    "    image_array = img_to_array(image)  # Convert to numpy array\n",
    "    image_array = np.expand_dims(image_array, axis=0)  # Add batch dimension\n",
    "    image_array = preprocess_input(image_array)  # Normalize for VGG19\n",
    "\n",
    "    # Perform inference\n",
    "    predictions = model(image_array, training=False)  # Inference mode\n",
    "    probabilities = tf.nn.softmax(predictions[0]).numpy()  # Apply softmax\n",
    "    predicted_class = np.argmax(probabilities)\n",
    "\n",
    "    # Print the predicted class and probabilities\n",
    "    print(f\"Predicted Class: {class_names[predicted_class]}\")\n",
    "    print(f\"Probabilities: {probabilities}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabc9a36-1dd7-4444-b8e4-95925809e750",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'BrainTumor_MRI/Testing/meningioma/Te-me_0073.jpg'\n",
    "predict_image(image_path, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd3af40-c27e-4a7c-83a7-99ec4120a566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
