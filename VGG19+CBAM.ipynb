{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5b4eed6-2685-496c-b83a-db73b1d23e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 14:30:04.395655: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-04 14:30:05.561098: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# ----------------- Import Libraries -----------------\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score, classification_report\n",
    "\n",
    "import seaborn as sns\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9de7fb9b-1571-4cda-89a4-f76256ca4962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- CBAM Block Definition -----------------\n",
    "def cbam_block(inputs, reduction_ratio=0.5):\n",
    "    channels = inputs.shape[-1]\n",
    "\n",
    "    # Channel Attention\n",
    "    avg_pool = layers.GlobalAveragePooling2D()(inputs)\n",
    "    max_pool = layers.GlobalMaxPooling2D()(inputs)\n",
    "    shared_layer_1 = layers.Dense(int(channels * reduction_ratio), activation='relu', use_bias=True)\n",
    "    shared_layer_2 = layers.Dense(channels, activation='relu', use_bias=True)\n",
    "\n",
    "    avg_pool = shared_layer_1(avg_pool)\n",
    "    avg_pool = shared_layer_2(avg_pool)\n",
    "    max_pool = shared_layer_1(max_pool)\n",
    "    max_pool = shared_layer_2(max_pool)\n",
    "\n",
    "    attention = layers.Add()([avg_pool, max_pool])\n",
    "    attention = layers.Activation('sigmoid')(attention)\n",
    "    attention = layers.Reshape((1, 1, channels))(attention)\n",
    "    scaled_inputs = layers.Multiply()([inputs, attention])\n",
    "\n",
    "    # Spatial Attention\n",
    "    squeeze = layers.Conv2D(filters=1, kernel_size=1, activation='sigmoid', use_bias=False)(scaled_inputs)\n",
    "    expanded_inputs = layers.Multiply()([scaled_inputs, squeeze])\n",
    "\n",
    "    return expanded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76da4805-8b0f-4a8d-b615-6b0bffb74111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG19_CBAM_Model():\n",
    "    input_shape = (224, 224, 3)\n",
    "    vgg19 = tf.keras.applications.VGG19(include_top=False, input_shape=input_shape, weights='imagenet')\n",
    "\n",
    "    x = cbam_block(vgg19.output)  # Apply CBAM block\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(units=1024, activation='relu')(x)\n",
    "    x = layers.Dense(units=512, activation='relu')(x)\n",
    "    x = layers.Dense(units=256, activation='relu')(x)\n",
    "    x = layers.Dense(units=128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.Dense(units=4, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs=vgg19.input, outputs=x, name='VGG19_CBAM_Model')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf8204f0-1683-4fa0-afc6-df378c974f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Compile and Train -----------------\n",
    "def compile_and_train(model, train_data, test_data, epochs=10, learning_rate=0.001):\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        validation_data=test_data,\n",
    "        epochs=epochs,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34d225bc-ba91-4b07-b8bf-6291957d6e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_global_model(model, test_loader, client_idx, output_dir=\"VGG19_model_results\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Ensure the output directory exists\n",
    "    output_file = os.path.join(output_dir, f\"Model_Results_Client_{client_idx + 1}.txt\")\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0\n",
    "\n",
    "    for features, labels in test_loader:\n",
    "        features_tf = tf.convert_to_tensor(features, dtype=tf.float32)\n",
    "\n",
    "        # Convert one-hot encoded labels to class indices\n",
    "        if len(labels.shape) > 1 and labels.shape[-1] > 1:  # Likely one-hot\n",
    "            labels_tf = tf.argmax(labels, axis=1, output_type=tf.int32)\n",
    "        else:\n",
    "            labels_tf = tf.convert_to_tensor(labels, dtype=tf.int32)\n",
    "\n",
    "        # Debugging: Print shapes\n",
    "        print(f\"Features shape: {features_tf.shape}, Labels shape: {labels_tf.shape}\")\n",
    "\n",
    "        # Get predictions\n",
    "        predictions = model(features_tf, training=False)\n",
    "        predicted = tf.argmax(predictions, axis=1, output_type=tf.int32)\n",
    "\n",
    "        # Accumulate predictions and labels\n",
    "        all_preds.extend(predicted.numpy())\n",
    "        all_labels.extend(labels_tf.numpy())\n",
    "\n",
    "\n",
    "        # Compute loss\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels_tf, logits=predictions)\n",
    "        total_loss += tf.reduce_mean(loss).numpy()\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # Classification report\n",
    "    class_names = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"] \n",
    "    classification_report_str = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "\n",
    "    # Append metrics to a file\n",
    "    with open(output_file, \"w\") as file:\n",
    "        file.write(f\"Evaluation Metrics for Client {client_idx + 1}:\\n\")\n",
    "        file.write(f\"Accuracy: {accuracy * 100:.2f}%\\n\")\n",
    "        file.write(f\"Loss: {total_loss / len(test_loader):.4f}\\n\")\n",
    "        file.write(f\"Precision: {precision:.4f}\\n\")\n",
    "        file.write(f\"Recall: {recall:.4f}\\n\")\n",
    "        file.write(f\"F1 Score: {f1:.4f}\\n\\n\")\n",
    "        file.write(\"Classification Report:\\n\")\n",
    "        file.write(classification_report_str)\n",
    "        file.write(\"\\nConfusion Matrix:\\n\")\n",
    "        file.write(\"\\n\".join([\"\\t\".join(map(str, row)) for row in conf_matrix]))\n",
    "        file.write(\"\\n\" + \"-\" * 50 + \"\\n\")\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"\\nClassification Report:\\n\", classification_report_str)\n",
    "    print(f\"\\nAccuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Loss: {total_loss / len(test_loader):.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Plot and save heatmap\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title(f'Confusion Matrix (Client {client_idx + 1})')\n",
    "    plt.savefig(os.path.join(output_dir, f\"confusion_matrix_Client_{client_idx + 1}.png\"))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1664a47d-5431-4f85-b573-a6df41260b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories for each client\n",
    "split_dirs = [\n",
    "    \"../NON_IID/Model_1\",\n",
    "    \"../NON_IID/Model_2\",\n",
    "    \"../NON_IID/Model_3\",\n",
    "    \"../NON_IID/Model_4\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fee69d24-4ea6-45db-b830-597d1636d3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 image sizes: torch.Size([25, 224, 224, 3])\n"
     ]
    }
   ],
   "source": [
    "# Updated image transformations: Normalize first, then permute\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),          # Convert image to tensor format (C, H, W)\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize\n",
    "    transforms.Lambda(lambda x: x.permute(1, 2, 0))  # Permute to (H, W, C)\n",
    "])\n",
    "\n",
    "def get_tumor_dataloaders(split_dirs, batch_size=25, shuffle=True):\n",
    "    \"\"\"\n",
    "    Returns data loaders for all clients for both training and testing sets.\n",
    "    \"\"\"\n",
    "    tumor_iid_train_dls = []\n",
    "    tumor_iid_test_dls = []\n",
    "\n",
    "    for client_idx, client_dir in enumerate(split_dirs):\n",
    "        # Get the directory for the current client\n",
    "        train_dir = os.path.join(client_dir, 'train')\n",
    "        test_dir = os.path.join(client_dir, 'test')\n",
    "\n",
    "        # Check if the directories exist\n",
    "        if not os.path.exists(train_dir) or not os.path.exists(test_dir):\n",
    "            print(f\"Directory not found for client {client_idx + 1}:\")\n",
    "            print(f\"Train dir: {train_dir}\")\n",
    "            print(f\"Test dir: {test_dir}\")\n",
    "            continue\n",
    "\n",
    "        # Load training data for the current client\n",
    "        train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "        # Load testing data for the current client\n",
    "        test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Append the dataloaders for the current client to the list\n",
    "        tumor_iid_train_dls.append(train_loader)\n",
    "        tumor_iid_test_dls.append(test_loader)\n",
    "\n",
    "    return tumor_iid_train_dls, tumor_iid_test_dls\n",
    "\n",
    "# Get the training and testing data loaders\n",
    "Tumor_iid_train_dls, Tumor_iid_test_dls = get_tumor_dataloaders(split_dirs, batch_size=25)\n",
    "\n",
    "# Checking the sizes of the images in the data loaders to verify the shape\n",
    "for batch_idx, (images, labels) in enumerate(Tumor_iid_train_dls[0]):  # Checking for client 1\n",
    "    print(f\"Batch {batch_idx} image sizes: {images.size()}\")  # Should print torch.Size([25, 224, 224, 3])\n",
    "    break  # Check only the first batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9da9b54a-ac6d-4ab7-a354-54f6590b6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def pytorch_to_tf_dataset(pytorch_loader, num_classes):\n",
    "    \"\"\"\n",
    "    Converts a PyTorch DataLoader to a TensorFlow dataset with one-hot encoded labels.\n",
    "    \"\"\"\n",
    "    images, labels = [], []\n",
    "    for batch_images, batch_labels in pytorch_loader:\n",
    "        # Convert PyTorch tensors to NumPy arrays and permute to (Batch, Height, Width, Channels)\n",
    "        images.append(batch_images.permute(0, 2, 1, 3).numpy())\n",
    "        # One-hot encode labels\n",
    "        labels.append(to_categorical(batch_labels.numpy(), num_classes=num_classes))\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    images = np.concatenate(images, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    \n",
    "    # Create TensorFlow dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    return dataset.batch(pytorch_loader.batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21ba6287-ed24-40b8-a2b9-70b0be50f0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and testing on dataset: Model_1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 14:30:20.187103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31132 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80134624/80134624 [==============================] - 6s 0us/step\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 14:30:33.349573: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [1321,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2024-12-04 14:30:36.841857: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n",
      "2024-12-04 14:30:41.929450: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f5324067170 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-04 14:30:41.929490: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-12-04 14:30:41.935167: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-04 14:30:42.100228: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - ETA: 0s - loss: 0.6715 - accuracy: 0.7600"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 14:31:30.181758: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [342,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 63s 822ms/step - loss: 0.6715 - accuracy: 0.7600 - val_loss: 0.7953 - val_accuracy: 0.6140\n",
      "Epoch 2/10\n",
      "53/53 [==============================] - 29s 552ms/step - loss: 0.5616 - accuracy: 0.7941 - val_loss: 0.7183 - val_accuracy: 0.6550\n",
      "Epoch 3/10\n",
      "53/53 [==============================] - 29s 550ms/step - loss: 0.4773 - accuracy: 0.8168 - val_loss: 0.6714 - val_accuracy: 0.7222\n",
      "Epoch 4/10\n",
      "53/53 [==============================] - 29s 551ms/step - loss: 0.4809 - accuracy: 0.8372 - val_loss: 0.5386 - val_accuracy: 0.8304\n",
      "Epoch 5/10\n",
      "53/53 [==============================] - 29s 549ms/step - loss: 0.3885 - accuracy: 0.8622 - val_loss: 0.5496 - val_accuracy: 0.7982\n",
      "Epoch 6/10\n",
      "53/53 [==============================] - 29s 549ms/step - loss: 0.3399 - accuracy: 0.8804 - val_loss: 0.5696 - val_accuracy: 0.7924\n",
      "Epoch 7/10\n",
      "53/53 [==============================] - 29s 549ms/step - loss: 0.3320 - accuracy: 0.8872 - val_loss: 0.5939 - val_accuracy: 0.7924\n",
      "Epoch 8/10\n",
      "53/53 [==============================] - 29s 551ms/step - loss: 0.2648 - accuracy: 0.9039 - val_loss: 0.3826 - val_accuracy: 0.8538\n",
      "Epoch 9/10\n",
      "53/53 [==============================] - 29s 550ms/step - loss: 0.2496 - accuracy: 0.9031 - val_loss: 0.3250 - val_accuracy: 0.8713\n",
      "Epoch 10/10\n",
      "53/53 [==============================] - 29s 550ms/step - loss: 0.2329 - accuracy: 0.9061 - val_loss: 0.3127 - val_accuracy: 0.8860\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (17, 224, 224, 3), Labels shape: (17,)\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.89      1.00      0.94       210\n",
      "  meningioma       0.86      0.19      0.31        32\n",
      "     notumor       0.83      0.98      0.90        50\n",
      "   pituitary       0.93      0.78      0.85        50\n",
      "\n",
      "    accuracy                           0.89       342\n",
      "   macro avg       0.88      0.74      0.75       342\n",
      "weighted avg       0.89      0.89      0.86       342\n",
      "\n",
      "\n",
      "Accuracy: 88.60%\n",
      "Loss: 0.8991\n",
      "Precision: 0.8858\n",
      "Recall: 0.8860\n",
      "F1 Score: 0.8623\n",
      "Training and evaluation completed for Model_1\n",
      "\n",
      "\n",
      "Training and testing on dataset: Model_2\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 14:36:33.998210: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [1339,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - ETA: 0s - loss: 0.8939 - accuracy: 0.7595"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 14:37:15.110595: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [340,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 47s 743ms/step - loss: 0.8939 - accuracy: 0.7595 - val_loss: 1.0523 - val_accuracy: 0.6176\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 29s 544ms/step - loss: 0.7036 - accuracy: 0.7760 - val_loss: 0.9898 - val_accuracy: 0.6176\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 29s 545ms/step - loss: 0.6564 - accuracy: 0.7730 - val_loss: 0.9800 - val_accuracy: 0.6176\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 29s 544ms/step - loss: 0.6380 - accuracy: 0.7767 - val_loss: 1.0231 - val_accuracy: 0.6176\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 29s 545ms/step - loss: 0.5775 - accuracy: 0.7894 - val_loss: 0.7886 - val_accuracy: 0.7088\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 29s 544ms/step - loss: 0.5004 - accuracy: 0.8096 - val_loss: 0.8465 - val_accuracy: 0.7500\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 29s 544ms/step - loss: 0.4972 - accuracy: 0.8335 - val_loss: 0.6770 - val_accuracy: 0.7588\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 29s 545ms/step - loss: 0.3647 - accuracy: 0.8940 - val_loss: 0.6082 - val_accuracy: 0.8265\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 29s 543ms/step - loss: 0.5089 - accuracy: 0.8484 - val_loss: 0.6873 - val_accuracy: 0.7441\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 29s 545ms/step - loss: 0.3198 - accuracy: 0.8969 - val_loss: 0.4724 - val_accuracy: 0.8500\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (15, 224, 224, 3), Labels shape: (15,)\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.75      0.50      0.60        30\n",
      "  meningioma       0.88      0.91      0.90       210\n",
      "     notumor       0.73      0.82      0.77        50\n",
      "   pituitary       0.89      0.82      0.85        50\n",
      "\n",
      "    accuracy                           0.85       340\n",
      "   macro avg       0.81      0.76      0.78       340\n",
      "weighted avg       0.85      0.85      0.85       340\n",
      "\n",
      "\n",
      "Accuracy: 85.00%\n",
      "Loss: 0.9239\n",
      "Precision: 0.8489\n",
      "Recall: 0.8500\n",
      "F1 Score: 0.8465\n",
      "Training and evaluation completed for Model_2\n",
      "\n",
      "\n",
      "Training and testing on dataset: Model_3\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 14:42:17.946613: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [1595,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - ETA: 0s - loss: 0.6079 - accuracy: 0.7605"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 14:43:07.445519: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [367,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 53s 709ms/step - loss: 0.6079 - accuracy: 0.7605 - val_loss: 0.7963 - val_accuracy: 0.6948\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 35s 545ms/step - loss: 0.4005 - accuracy: 0.8188 - val_loss: 0.5599 - val_accuracy: 0.7221\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 35s 546ms/step - loss: 0.3629 - accuracy: 0.8458 - val_loss: 0.5103 - val_accuracy: 0.7384\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 35s 543ms/step - loss: 0.3185 - accuracy: 0.8652 - val_loss: 0.5494 - val_accuracy: 0.7657\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 35s 544ms/step - loss: 0.3047 - accuracy: 0.8621 - val_loss: 0.5886 - val_accuracy: 0.7657\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 35s 545ms/step - loss: 0.2974 - accuracy: 0.8702 - val_loss: 0.4467 - val_accuracy: 0.7847\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 35s 545ms/step - loss: 0.2746 - accuracy: 0.8803 - val_loss: 0.4250 - val_accuracy: 0.7684\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 35s 543ms/step - loss: 0.3125 - accuracy: 0.8677 - val_loss: 0.4554 - val_accuracy: 0.7956\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 35s 543ms/step - loss: 0.3070 - accuracy: 0.8696 - val_loss: 0.4685 - val_accuracy: 0.8011\n",
      "Epoch 10/10\n",
      "64/64 [==============================] - 35s 543ms/step - loss: 0.2703 - accuracy: 0.8821 - val_loss: 0.4626 - val_accuracy: 0.8202\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (17, 224, 224, 3), Labels shape: (17,)\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.55      0.53      0.54        30\n",
      "  meningioma       0.67      0.06      0.11        32\n",
      "     notumor       0.88      1.00      0.94       255\n",
      "   pituitary       0.61      0.56      0.58        50\n",
      "\n",
      "    accuracy                           0.82       367\n",
      "   macro avg       0.68      0.54      0.54       367\n",
      "weighted avg       0.80      0.82      0.79       367\n",
      "\n",
      "\n",
      "Accuracy: 82.02%\n",
      "Loss: 0.9489\n",
      "Precision: 0.7992\n",
      "Recall: 0.8202\n",
      "F1 Score: 0.7852\n",
      "Training and evaluation completed for Model_3\n",
      "\n",
      "\n",
      "Training and testing on dataset: Model_4\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 14:48:50.576753: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [1457,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - ETA: 0s - loss: 0.6386 - accuracy: 0.7865"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 14:49:32.132338: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [262,4]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 46s 657ms/step - loss: 0.6386 - accuracy: 0.7865 - val_loss: 0.7076 - val_accuracy: 0.6756\n",
      "Epoch 2/10\n",
      "59/59 [==============================] - 31s 532ms/step - loss: 0.3989 - accuracy: 0.8483 - val_loss: 0.7389 - val_accuracy: 0.7863\n",
      "Epoch 3/10\n",
      "59/59 [==============================] - 31s 532ms/step - loss: 0.3638 - accuracy: 0.8703 - val_loss: 0.7830 - val_accuracy: 0.7786\n",
      "Epoch 4/10\n",
      "59/59 [==============================] - 31s 533ms/step - loss: 0.3191 - accuracy: 0.8881 - val_loss: 0.6753 - val_accuracy: 0.8206\n",
      "Epoch 5/10\n",
      "59/59 [==============================] - 31s 532ms/step - loss: 0.2521 - accuracy: 0.9218 - val_loss: 0.6092 - val_accuracy: 0.8168\n",
      "Epoch 6/10\n",
      "59/59 [==============================] - 31s 532ms/step - loss: 0.2418 - accuracy: 0.9218 - val_loss: 0.4005 - val_accuracy: 0.8435\n",
      "Epoch 7/10\n",
      "59/59 [==============================] - 31s 532ms/step - loss: 0.2251 - accuracy: 0.9341 - val_loss: 0.3847 - val_accuracy: 0.8740\n",
      "Epoch 8/10\n",
      "59/59 [==============================] - 31s 534ms/step - loss: 0.1782 - accuracy: 0.9499 - val_loss: 0.3160 - val_accuracy: 0.8702\n",
      "Epoch 9/10\n",
      "59/59 [==============================] - 31s 531ms/step - loss: 0.1312 - accuracy: 0.9609 - val_loss: 0.3865 - val_accuracy: 0.8702\n",
      "Epoch 10/10\n",
      "59/59 [==============================] - 31s 532ms/step - loss: 0.1058 - accuracy: 0.9705 - val_loss: 0.6958 - val_accuracy: 0.8588\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (25, 224, 224, 3), Labels shape: (25,)\n",
      "Features shape: (12, 224, 224, 3), Labels shape: (12,)\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      glioma       1.00      0.47      0.64        30\n",
      "  meningioma       0.79      0.47      0.59        32\n",
      "     notumor       0.90      0.92      0.91        50\n",
      "   pituitary       0.84      1.00      0.91       150\n",
      "\n",
      "    accuracy                           0.86       262\n",
      "   macro avg       0.88      0.71      0.76       262\n",
      "weighted avg       0.87      0.86      0.84       262\n",
      "\n",
      "\n",
      "Accuracy: 85.88%\n",
      "Loss: 0.8756\n",
      "Precision: 0.8655\n",
      "Recall: 0.8588\n",
      "F1 Score: 0.8422\n",
      "Training and evaluation completed for Model_4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Iterate over all client datasets\n",
    "    for client_idx in range(len(split_dirs)):\n",
    "        print(f\"\\nTraining and testing on dataset: Model_{client_idx + 1}\\n\")\n",
    "        \n",
    "        # Load data for the current client\n",
    "        train_loader = Tumor_iid_train_dls[client_idx]\n",
    "        test_loader = Tumor_iid_test_dls[client_idx]\n",
    "\n",
    "        # Number of classes in your dataset\n",
    "        num_classes = 4\n",
    "\n",
    "        # Convert PyTorch DataLoaders to TensorFlow datasets\n",
    "        tf_train_dataset = pytorch_to_tf_dataset(train_loader, num_classes)\n",
    "        tf_test_dataset = pytorch_to_tf_dataset(test_loader, num_classes)\n",
    "\n",
    "        # Build Model\n",
    "        model = VGG19_CBAM_Model()\n",
    "\n",
    "        # Use these datasets for training\n",
    "        history = compile_and_train(model, tf_train_dataset, tf_test_dataset, epochs=10, learning_rate=0.0001)\n",
    "\n",
    "        # Evaluate and Save Results\n",
    "        evaluate_global_model(model, tf_test_dataset, client_idx, output_dir=\"VGG19_model_results\")\n",
    "\n",
    "        print(f\"Training and evaluation completed for Model_{client_idx + 1}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec53d8e1-118d-4f39-b25a-008876dabe47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
