{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f71c206-ab25-4aff-92ee-3bbde084bc8a",
   "metadata": {},
   "source": [
    "# Import Libraries & methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8855f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Flatten, Input, BatchNormalization, Dense, Activation, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from copy import deepcopy\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39974288-942d-48f4-af88-592ec2b24a21",
   "metadata": {},
   "source": [
    "### Methods used in FedProx Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146a4e25-c86e-476c-a8c1-933df291a0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_classifier(predictions, labels):\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=predictions)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "def loss_dataset(model, dataset, loss_f):\n",
    "    loss = 0\n",
    "    for idx, (features, labels) in enumerate(dataset):\n",
    "        # Convert PyTorch tensors to NumPy and then to TensorFlow tensors\n",
    "        features_np = features.detach().cpu().numpy()\n",
    "        labels_np = labels.detach().cpu().numpy()\n",
    "\n",
    "        features_tf = tf.convert_to_tensor(features_np, dtype=tf.float32)\n",
    "        labels_tf = tf.convert_to_tensor(labels_np, dtype=tf.int32)\n",
    "\n",
    "        predictions = model(features_tf)\n",
    "        loss += loss_f(predictions, labels_tf)\n",
    "    loss /= (idx + 1)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def accuracy_dataset(model, dataset):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for features, labels in dataset:\n",
    "        # Convert PyTorch tensors to NumPy and then to TensorFlow tensors\n",
    "        features_np = features.detach().cpu().numpy()\n",
    "        labels_np = labels.detach().cpu().numpy()\n",
    "\n",
    "        features_tf = tf.convert_to_tensor(features_np, dtype=tf.float32)\n",
    "        labels_tf = tf.convert_to_tensor(labels_np, dtype=tf.int32)\n",
    "\n",
    "        predictions = model(features_tf)\n",
    "        predicted = tf.argmax(predictions, axis=1, output_type=tf.int32)\n",
    "        correct += tf.reduce_sum(tf.cast(tf.equal(predicted, labels_tf), tf.int32)).numpy()\n",
    "        total += labels_tf.shape[0]\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def train_step(model, model_0, mu, optimizer, train_data, loss_f):\n",
    "    total_loss = 0\n",
    "    for idx, (features, labels) in enumerate(train_data):\n",
    "        # Convert PyTorch tensors to NumPy and then to TensorFlow tensors\n",
    "        features_np = features.detach().cpu().numpy()\n",
    "        labels_np = labels.detach().cpu().numpy()\n",
    "\n",
    "        features_tf = tf.convert_to_tensor(features_np, dtype=tf.float32)\n",
    "        labels_tf = tf.convert_to_tensor(labels_np, dtype=tf.int32)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(features_tf)\n",
    "            loss = loss_f(predictions, labels_tf)\n",
    "            loss += mu / 2 * difference_models_norm_2(model, model_0)\n",
    "\n",
    "        total_loss += loss\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return total_loss / (idx + 1)\n",
    "\n",
    "\n",
    "def local_learning(model, mu, optimizer, train_data, epochs, loss_f):\n",
    "    # (No longer used by FedProx, but left intact)\n",
    "    model_0 = tf.keras.models.clone_model(model)\n",
    "    model_0.set_weights(model.get_weights())\n",
    "\n",
    "    for e in range(epochs):\n",
    "        local_loss = train_step(model, model_0, mu, optimizer, train_data, loss_f)\n",
    "\n",
    "    return local_loss\n",
    "\n",
    "\n",
    "def difference_models_norm_2(model_1, model_2):\n",
    "    norm = tf.reduce_sum([tf.reduce_sum(tf.square(w1 - w2))\n",
    "                          for w1, w2 in zip(model_1.trainable_variables, model_2.trainable_variables)])\n",
    "    return norm\n",
    "\n",
    "\n",
    "def set_to_zero_model_weights(model):\n",
    "    for layer_weights in model.trainable_variables:\n",
    "        layer_weights.assign(tf.zeros_like(layer_weights))\n",
    "\n",
    "\n",
    "def average_models(model, clients_models_hist, weights):\n",
    "    set_to_zero_model_weights(model)\n",
    "    for k, client_hist in enumerate(clients_models_hist):\n",
    "        for idx, layer_weights in enumerate(model.trainable_variables):\n",
    "            contribution = client_hist[idx] * weights[k]\n",
    "            layer_weights.assign_add(contribution)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4f2bec",
   "metadata": {},
   "source": [
    "### Federated Proximal Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c4bf4c-4d12-4942-98b0-6a4c65695cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FedProx(model, training_sets, n_iter, testing_sets, mu=0.1, epochs=1, lr=0.0001, decay=1):\n",
    "    # Verify that `model` is a Keras model instance\n",
    "    if not isinstance(model, tf.keras.Model):\n",
    "        raise TypeError(\"The provided model is not a TensorFlow Keras model. Please provide a valid Keras model.\")\n",
    "\n",
    "    loss_f = loss_classifier\n",
    "    K = len(training_sets)\n",
    "    n_samples = sum([len(db) for db in training_sets])\n",
    "    weights = [len(db) / n_samples for db in training_sets]\n",
    "    print(\"Clients' weights:\", weights)\n",
    "\n",
    "    # Initialize history lists for training and testing\n",
    "    train_loss_hist = []\n",
    "    train_acc_hist = []\n",
    "    test_loss_hist = []\n",
    "    test_acc_hist = []\n",
    "    models_hist = []\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        clients_params = []\n",
    "        clients_losses = []\n",
    "        clients_accuracies = []\n",
    "\n",
    "        for k in range(K):\n",
    "            # Clone the global model for local training\n",
    "            local_model = tf.keras.models.clone_model(model)\n",
    "            local_model.set_weights(model.get_weights())\n",
    "\n",
    "            # ---- Two‐Phase Local Update ----\n",
    "            # Prepare a copy of initial weights for FedProx proximal term\n",
    "            model_0 = tf.keras.models.clone_model(local_model)\n",
    "            model_0.set_weights(local_model.get_weights())\n",
    "\n",
    "            # # Phase 1: freeze backbone, train 5 epochs at lr=1e-3\n",
    "            local_model.layers[1].trainable = False\n",
    "            optimizer1 = tf.keras.optimizers.Adam(1e-3)\n",
    "            for _ in range(1):\n",
    "                local_loss = train_step(local_model, model_0, mu, optimizer1, training_sets[k], loss_f)\n",
    "\n",
    "            # Phase 2: unfreeze backbone, train `epochs` epochs at lr=1e-4\n",
    "            local_model.layers[1].trainable = True\n",
    "            optimizer2 = tf.keras.optimizers.SGD(learning_rate=1e-4, momentum=0.9)\n",
    "            for _ in range(epochs):\n",
    "                local_loss = train_step(local_model, model_0, mu, optimizer2, training_sets[k], loss_f)\n",
    "\n",
    "            clients_losses.append(local_loss)\n",
    "\n",
    "            # Track training accuracy for the client\n",
    "            train_acc = accuracy_dataset(local_model, training_sets[k])\n",
    "            clients_accuracies.append(train_acc)\n",
    "\n",
    "            # Store model parameters\n",
    "            clients_params.append([tf.identity(tens_param) for tens_param in local_model.trainable_variables])\n",
    "        # ------------------------------\n",
    "\n",
    "        # Aggregate back to the global model\n",
    "        average_models(model, clients_params, weights=weights)\n",
    "        models_hist.append(deepcopy(clients_params))\n",
    "\n",
    "        # Record metrics\n",
    "        train_loss_hist.append(clients_losses)\n",
    "        train_acc_hist.append(clients_accuracies)\n",
    "\n",
    "        test_loss_hist.append([loss_dataset(model, dl, loss_f).numpy() for dl in testing_sets])\n",
    "        test_acc_hist.append([accuracy_dataset(model, dl) for dl in testing_sets])\n",
    "\n",
    "        lr *= decay\n",
    "        print(f'====> Round {i+1} Server Test Accuracy: {test_acc_hist[-1]}')\n",
    "\n",
    "    return model, train_loss_hist, train_acc_hist, test_loss_hist, test_acc_hist\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dfbd41-5dc5-432d-80a7-2d1adb20ace1",
   "metadata": {},
   "source": [
    "# To save model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4371450-b7db-442a-869d-2725b3553a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the history to a file with detailed formatting\n",
    "def save_history_to_file(filename, train_loss, train_acc, test_loss, test_acc):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"FedProx Training and Testing Metrics\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\")\n",
    "        \n",
    "        for i in range(len(train_loss)):\n",
    "            try:\n",
    "                train_loss_str = [float(tensor.numpy()) if hasattr(tensor, 'numpy') else float(tensor) \n",
    "                                  for tensor in train_loss[i]]\n",
    "                train_acc_str  = [float(val) for val in train_acc[i]]\n",
    "                test_loss_str  = [float(val) for val in test_loss[i]]\n",
    "                test_acc_str   = [float(val) for val in test_acc[i]]\n",
    "                \n",
    "                f.write(f\"Iteration {i + 1}:\\n\")\n",
    "                f.write(f\"Train Loss: {train_loss_str}\\n\")\n",
    "                f.write(f\"Train Accuracy: {train_acc_str}\\n\")\n",
    "                f.write(f\"Test Loss: {test_loss_str}\\n\")\n",
    "                f.write(f\"Test Accuracy: {test_acc_str}\\n\")\n",
    "                f.write(\"-\" * 50 + \"\\n\")\n",
    "                \n",
    "            except (ValueError, TypeError) as e:\n",
    "                f.write(f\"Error processing round {i + 1}: {e}\\n\")\n",
    "                f.write(\"-\" * 50 + \"\\n\")\n",
    "    \n",
    "    print(f\"History saved to {filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f485cd-e3f3-45fa-81b9-222579b3ff23",
   "metadata": {},
   "source": [
    "# Load training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288cbe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories for each client\n",
    "split_dirs = [\n",
    "    \"NON_IID/Model_1\",\n",
    "    \"NON_IID/Model_2\",\n",
    "    \"NON_IID/Model_3\",\n",
    "    \"NON_IID/Model_4\"\n",
    "]\n",
    "\n",
    "# Number of clients\n",
    "n_clients = len(split_dirs)\n",
    "\n",
    "# Updated image transformations: Normalize first, then permute\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),          \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "    transforms.Lambda(lambda x: x.permute(1, 2, 0))\n",
    "])\n",
    "\n",
    "def get_tumor_dataloaders(split_dirs, batch_size=25, shuffle=True):\n",
    "    tumor_iid_train_dls = []\n",
    "    tumor_iid_test_dls = []\n",
    "\n",
    "    for client_idx, client_dir in enumerate(split_dirs):\n",
    "        train_dir = os.path.join(client_dir, 'train')\n",
    "        test_dir  = os.path.join(client_dir, 'test')\n",
    "\n",
    "        if not os.path.exists(train_dir) or not os.path.exists(test_dir):\n",
    "            print(f\"Directory not found for client {client_idx + 1}: {train_dir}, {test_dir}\")\n",
    "            continue\n",
    "\n",
    "        train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "        train_loader  = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "        test_dataset  = datasets.ImageFolder(test_dir,  transform=transform)\n",
    "        test_loader   = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        tumor_iid_train_dls.append(train_loader)\n",
    "        tumor_iid_test_dls.append(test_loader)\n",
    "\n",
    "    return tumor_iid_train_dls, tumor_iid_test_dls\n",
    "\n",
    "Tumor_iid_train_dls, Tumor_iid_test_dls = get_tumor_dataloaders(split_dirs, batch_size=25)\n",
    "\n",
    "for batch_idx, (images, labels) in enumerate(Tumor_iid_train_dls[0]):\n",
    "    print(f\"Batch {batch_idx} image sizes: {images.size()}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f658c8fb-cc6b-466e-9163-1b0bf7b43c9b",
   "metadata": {},
   "source": [
    "# ResNet50 model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee94b47f-44c3-45ef-b060-e88e6290cc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Model Definition ------------------\n",
    "def ResNet50_Model():\n",
    "    input_shape = (224, 224, 3)\n",
    "    base_model = tf.keras.applications.ResNet50(\n",
    "        include_top=False,\n",
    "        input_shape=input_shape,\n",
    "        weights='imagenet'\n",
    "    )\n",
    " \n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    x = layers.Dense(1024, activation='relu')(x)\n",
    "    x = layers.Dense(512,  activation='relu')(x)\n",
    "    x = layers.Dense(256,  activation='relu')(x)\n",
    "    x = layers.Dense(128,  activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    # Optional dense attention head\n",
    "    x = layers.Reshape((1, 1, 128))(x)\n",
    "    x_max = layers.GlobalMaxPooling2D()(x)\n",
    "    x_avg = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Concatenate()([x_max, x_avg])\n",
    "\n",
    "    outputs = layers.Dense(4, activation='softmax')(x)\n",
    "    return models.Model(inputs=base_model.input, outputs=outputs, name='ResNet50_Model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7380c4c8-86bf-4300-8147-98a3ee95ed7b",
   "metadata": {},
   "source": [
    "# Model Intialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1038383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate & compile the global model\n",
    "model = ResNet50_Model()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a4a26-e380-443e-9b70-a236426e1747",
   "metadata": {},
   "source": [
    "# Load original testing dataset (without augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7255b70-43fc-41be-9f1c-ac46cf016964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),          # Convert image to tensor format (C, H, W)\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize\n",
    "    transforms.Lambda(lambda x: x.permute(1, 2, 0))  # Permute to (H, W, C)\n",
    "])\n",
    "\n",
    "# Load the testing dataset\n",
    "test_dir = 'BrainTumor_MRI/Testing'\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Class names mapping (adjust if necessary)\n",
    "class_names = test_dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77d67c7-7b56-4639-9a45-136b43ed70a8",
   "metadata": {},
   "source": [
    "# To evaluate the trained model\n",
    "# Save the confusion matrix + performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da4a128-b9ec-408f-a166-e0a1bc6c0746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class names\n",
    "class_names = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]  # Modify according to your classes\n",
    "MODEL_PATH = 'model_results_mu=1.0/'\n",
    "\n",
    "# Function to evaluate the global model on the testing dataset\n",
    "def evaluate_global_model(model, test_loader, output_file=f'{MODEL_PATH}Global_Model_Results_mu=1.0.txt'):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0\n",
    "\n",
    "    for features, labels in test_loader:\n",
    "        # Convert to TensorFlow tensors\n",
    "        features_np = features.detach().cpu().numpy()\n",
    "        labels_np = labels.detach().cpu().numpy()\n",
    "\n",
    "        features_tf = tf.convert_to_tensor(features_np, dtype=tf.float32)\n",
    "        labels_tf = tf.convert_to_tensor(labels_np, dtype=tf.int32)\n",
    "\n",
    "        # Get predictions\n",
    "        predictions = model(features_tf)\n",
    "        predicted = tf.argmax(predictions, axis=1, output_type=tf.int32)\n",
    "\n",
    "        # Accumulate predictions and labels\n",
    "        all_preds.extend(predicted.numpy())\n",
    "        all_labels.extend(labels_np)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels_tf, logits=predictions)\n",
    "        total_loss += tf.reduce_mean(loss).numpy()\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    # Classification report\n",
    "    classification_report_str = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "\n",
    "    # Append metrics to a file\n",
    "    with open(output_file, \"a\") as file:\n",
    "        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')  # Get current timestamp\n",
    "        file.write(f\"Evaluation Timestamp: {timestamp}\\n\")\n",
    "        file.write(\"Evaluation Metrics:\\n\")\n",
    "        file.write(f\"Accuracy: {accuracy * 100:.2f}%\\n\")\n",
    "        file.write(f\"Loss: {total_loss / len(test_loader):.4f}\\n\")\n",
    "        file.write(f\"Precision: {precision:.4f}\\n\")\n",
    "        file.write(f\"Recall: {recall:.4f}\\n\")\n",
    "        file.write(f\"F1 Score: {f1:.4f}\\n\\n\")\n",
    "        file.write(\"Classification Report:\\n\")\n",
    "        file.write(classification_report_str)\n",
    "        file.write(\"\\nConfusion Matrix:\\n\")\n",
    "        file.write(\"\\n\".join([\"\\t\".join(map(str, row)) for row in conf_matrix]))\n",
    "        file.write(\"\\n\" + \"-\" * 50 + \"\\n\")\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"\\nClassification Report:\\n\", classification_report_str)\n",
    "    print(f\"\\nAccuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Loss: {total_loss / len(test_loader):.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Plot and save heatmap\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    heatmap_path = f'model_results_mu=1.0/confusion_matrix_{timestamp.replace(\" \", \"_\").replace(\":\", \"-\")}.png'\n",
    "    plt.savefig(heatmap_path)  # Save as PNG with timestamp\n",
    "    plt.close()  # Close the figure\n",
    "    \n",
    "    current_loss = (total_loss / len(test_loader))\n",
    "    return current_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f596786-1c87-406c-9ba2-cbc7a2cefbd5",
   "metadata": {},
   "source": [
    "# FedProx hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8558fd6a-9a45-4198-9496-7a5d27b69bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial parameters\n",
    "MODEL_PATH = 'model_results_mu=1.0/' # to save the model\n",
    "n_iter = 100\n",
    "rounds_per_segment = 5 # for every 5 rounds global model will evalaute and save results\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf794472-b888-4ab1-bc5a-81ada0e6a7fb",
   "metadata": {},
   "source": [
    "### mu & learning rate\n",
    "\n",
    "### change the mu value like mu=0 || mu=0.1 || mu=0.4 || mu=0.7 || mu=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508a715d-bd60-4283-935f-b3474cda4aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "mu = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d1e2a0-6b8d-4de4-bb1b-81581aac34f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store cumulative training and testing metrics\n",
    "all_train_loss = []\n",
    "all_train_acc = []\n",
    "all_test_loss = []\n",
    "all_test_acc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d2a449-a99e-4410-ae90-b76ae7c5f994",
   "metadata": {},
   "source": [
    "## 100 rounds training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5051613b-226d-444d-9547-e39ada96e642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize early stopping parameters\n",
    "patience = 20\n",
    "best_metric = None  # Track the lowest validation loss\n",
    "no_improve_rounds = 0  # Counter for rounds without improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028b4e91",
   "metadata": {},
   "source": [
    "### Load the model if the training is stoped in the middle beacuse of memory exhaust or any interuption. Then use below code to load the saved model in last round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b75771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model('model_results_mu=1.0/best_model_rounds_5_mu=1.0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c99998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for FedProx training in segments\n",
    "for i in range(0, n_iter, rounds_per_segment):\n",
    "    print(f\"Starting rounds {i+1} to {i+rounds_per_segment}\")\n",
    "    \n",
    "    # Train for the specified number of rounds in this segment\n",
    "    model, train_loss_f, train_acc_f, test_loss_f, test_acc_f = FedProx(\n",
    "        model, Tumor_iid_train_dls, rounds_per_segment, Tumor_iid_test_dls, mu=mu, epochs=epochs, lr=lr\n",
    "    )\n",
    "    \n",
    "    # Append the metrics to the cumulative lists\n",
    "    all_train_loss.extend(train_loss_f)\n",
    "    all_train_acc.extend(train_acc_f)\n",
    "    all_test_loss.extend(test_loss_f)\n",
    "    all_test_acc.extend(test_acc_f)\n",
    "    \n",
    "    # Save the model at the end of each segment\n",
    "    segment_model_path = f'{MODEL_PATH}global_model_rounds_{i+rounds_per_segment}_mu={mu}.h5'\n",
    "    model.save(segment_model_path)\n",
    "    print(f\"Model saved at: {segment_model_path}\")\n",
    "    \n",
    "    # Test the saved global model on the testing dataset\n",
    "    print(f\"Evaluating global model for rounds {i+1} to {i+rounds_per_segment}\")\n",
    "    current_metric = evaluate_global_model(model, test_loader, output_file=f'{MODEL_PATH}Global_Model_Results_mu={mu}.txt')\n",
    "    \n",
    "    # Check for early stopping based on validation loss. Use the most recent validation loss\n",
    "    print(f\"Current validation loss: {current_metric:.4f}\")\n",
    "    \n",
    "    if best_metric is None or current_metric < best_metric:  # Improvement check\n",
    "        best_metric = current_metric\n",
    "        no_improve_rounds = 0  # Reset counter\n",
    "        # Save the best model\n",
    "        best_model_path = f'{MODEL_PATH}best_model_rounds_{i+rounds_per_segment}_mu={mu}.h5'\n",
    "        model.save(best_model_path)\n",
    "        print(f\"Best model updated and saved at: {best_model_path}\")\n",
    "    else:\n",
    "        no_improve_rounds += 1\n",
    "        print(f\"No improvement for {no_improve_rounds} rounds. Best validation loss: {best_metric:.4f}\")\n",
    "    \n",
    "    if no_improve_rounds >= patience:  # Early stopping condition\n",
    "        print(\"Early stopping triggered. Training stopped.\")\n",
    "        break\n",
    "    \n",
    "    # Reload the model to ensure continuity for the next segment\n",
    "    model = tf.keras.models.load_model(segment_model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2e66c9",
   "metadata": {},
   "source": [
    "### If training the model 100 rounds completed in one, save the performance metrics (Optional). Metrics of global model saved for every 5 rounds, during evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaf5eb2-fb47-4cb7-8a42-0a781464678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cumulative history to a file after all rounds are complete\n",
    "train_loss = all_train_loss[-100:]  # Adjusted to reflect 30 rounds for rounds 51 to 80\n",
    "train_acc = all_train_acc[-100:]\n",
    "test_loss = all_test_loss[-100:]\n",
    "test_acc = all_test_acc[-100:]\n",
    "\n",
    "# File to save the results\n",
    "output_file = f'{MODEL_PATH}results-mu={mu}_{len(train_loss)}_rounds.txt'\n",
    "\n",
    "# Save the data to the file\n",
    "save_history_to_file(output_file, train_loss, train_acc, test_loss, test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c08a858-daac-400f-8590-d4fe02749e60",
   "metadata": {},
   "source": [
    "# Load the trained model to test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a03a78f-25d8-4804-81c1-7251fe0cbd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = f'{MODEL_PATH}global_model_rounds_100_mu={mu}.h5'\n",
    "model = tf.keras.models.load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d64d0d-1d4b-4cc1-9610-6fb559614cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_global_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5a3bb6-3d7f-48b1-bc0e-525481ed94dd",
   "metadata": {},
   "source": [
    "# to check how good the model to predict the class of a random image from testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2de34a-7b24-4e5e-b881-8182da8ed04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class names\n",
    "class_names = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "\n",
    "# Function to predict the class of a single image\n",
    "def predict_image(image_path, model):\n",
    "    # Load and preprocess the image\n",
    "    image = load_img(image_path, target_size=(224, 224))  # Resize to 224x224\n",
    "    image_array = img_to_array(image)  # Convert to numpy array\n",
    "    image_array = np.expand_dims(image_array, axis=0)  # Add batch dimension\n",
    "    image_array = preprocess_input(image_array)  # Normalize for VGG19\n",
    "\n",
    "    # Perform inference\n",
    "    predictions = model(image_array, training=False)  # Inference mode\n",
    "    probabilities = tf.nn.softmax(predictions[0]).numpy()  # Apply softmax\n",
    "    predicted_class = np.argmax(probabilities)\n",
    "\n",
    "    # Print the predicted class and probabilities\n",
    "    print(f\"Predicted Class: {class_names[predicted_class]}\")\n",
    "    print(f\"Probabilities: {probabilities}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabc9a36-1dd7-4444-b8e4-95925809e750",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'BrainTumor_MRI/Testing/meningioma/Te-me_0073.jpg'\n",
    "predict_image(image_path, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
